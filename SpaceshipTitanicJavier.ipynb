{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic\n",
    "\n",
    "Our goal is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and Data Field Descriptions\n",
    "\n",
    "* **train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    * PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "    * HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    * CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    * Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    * Destination - The planet the passenger will be debarking to.\n",
    "    * Age - The age of the passenger.\n",
    "    * VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    * RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    * Name - The first and last names of the passenger.\n",
    "    * Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "* **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "* **sample_submission.csv** - A submission file in the correct format.\n",
    "    * PassengerId - Id for each passenger in the test set.\n",
    "    * Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T22:51:46.329307Z",
     "iopub.status.busy": "2025-04-17T22:51:46.328988Z",
     "iopub.status.idle": "2025-04-17T22:51:46.334775Z",
     "shell.execute_reply": "2025-04-17T22:51:46.333736Z",
     "shell.execute_reply.started": "2025-04-17T22:51:46.329278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset loading and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T22:53:41.701025Z",
     "iopub.status.busy": "2025-04-17T22:53:41.700621Z",
     "iopub.status.idle": "2025-04-17T22:53:41.799405Z",
     "shell.execute_reply": "2025-04-17T22:53:41.798601Z",
     "shell.execute_reply.started": "2025-04-17T22:53:41.701001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (8693, 14)\n",
      "Full test dataset shape is (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset into a Pandas Dataframe\n",
    "# Try to load the dataset from Kaggle, if not found, load from local directory\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.read_csv('kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('kaggle/input/spaceship-titanic/test.csv')\n",
    "\n",
    "print(\"Full train dataset shape is {}\".format(train_df.shape))\n",
    "print(\"Full test dataset shape is {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# I split the datasets into features (X) and tag (Y)\n",
    "train_x = train_df.drop(columns=['Transported'])\n",
    "train_y = train_df['Transported'].astype(int)  # Convert boolean to int (0 or 1)\n",
    "\n",
    "test_x = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the different models used, I split the training set into train and validation, giving a 10% of the samples to the validation set. I set that percentage in order to have a dataset big enough to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape is (7823, 13)\n",
      "Validation dataset shape is (870, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>4408_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/906/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pich Knike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7710_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/253/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>Chabih Eguing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>7709_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1238/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Sweett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>8512_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1637/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Verly Flyncharlan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0052_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/6/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elaney Hubbarton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4132     4408_01       Mars      True   F/906/P    TRAPPIST-1e  75.0  False   \n",
       "7217     7710_01     Europa     False   B/253/P    TRAPPIST-1e  27.0  False   \n",
       "7216     7709_02      Earth      True  G/1238/P  PSO J318.5-22  24.0  False   \n",
       "7968     8512_01      Earth     False  F/1637/S    55 Cancri e  48.0  False   \n",
       "50       0052_01      Earth     False     G/6/S    TRAPPIST-1e   NaN  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "4132          0.0        0.0           0.0     0.0     0.0         Pich Knike  \n",
       "7217        118.0     1769.0        4127.0   118.0   619.0      Chabih Eguing  \n",
       "7216          0.0        NaN           0.0     0.0     0.0      Lerome Sweett  \n",
       "7968          0.0      717.0           0.0     0.0    10.0  Verly Flyncharlan  \n",
       "50            4.0        0.0           2.0  4683.0     0.0   Elaney Hubbarton  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(\"Train dataset shape is {}\".format(train_x.shape))\n",
    "print(\"Validation dataset shape is {}\".format(val_x.shape))\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After separate a validation set from our training set, the next step is to preprocess the dataset, to do that I will check each individual feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId\n",
    "\n",
    "This variable represents a unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "At the begining it seems to be a variant without information to solve the problem, something like a name, however as it said, we can extract the number of members that each group has and that can be something relevant.\n",
    "However to know the number of members a group has, we have to use the whole dataset, trining + validation + test sets. To do this would be a problem in most cases because we are not sure that our dataset contain all the existent samples, however for this task, the description tells us that we have about two-thirds (~8700) of the passengers as the training set and THE REMAINING one-third (~4300) of the passengers as test, so we got at least partial information about all the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in PassengerId:\n",
      "train_x: 0\n",
      "test_x: 0\n",
      "val_x: 0\n",
      "Updated train_x:\n",
      "     PassengerId Group  numMembers\n",
      "4132     4408_01  4408           1\n",
      "7217     7710_01  7710           1\n",
      "7216     7709_02  7709           2\n",
      "7968     8512_01  8512           1\n",
      "50       0052_01  0052           1\n",
      "\n",
      "Updated val_x:\n",
      "     PassengerId Group  numMembers\n",
      "3601     3868_05  3868           7\n",
      "6057     6405_02  6405           4\n",
      "2797     3021_01  3021           2\n",
      "7110     7578_01  7578           1\n",
      "8579     9158_01  9158           1\n",
      "\n",
      "Updated test_x:\n",
      "  PassengerId Group  numMembers\n",
      "0     0013_01  0013           1\n",
      "1     0018_01  0018           1\n",
      "2     0019_01  0019           1\n",
      "3     0021_01  0021           1\n",
      "4     0023_01  0023           1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in PassengerId\n",
    "print(\"Missing values in PassengerId:\")\n",
    "print(f\"train_x: {train_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['PassengerId'].isnull().sum()}\")\n",
    "\n",
    "# Extract group identifier (gggg) from PassengerId\n",
    "train_x['Group'] = train_x['PassengerId'].str.split('_').str[0]\n",
    "test_x['Group'] = test_x['PassengerId'].str.split('_').str[0]\n",
    "val_x['Group'] = val_x['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "# Combine all dataframes to calculate group sizes across all datasets\n",
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Calculate the total number of members in each group\n",
    "group_sizes = combined_df['Group'].value_counts()\n",
    "\n",
    "# Add the numMembers column to each dataframe\n",
    "train_x['numMembers'] = train_x['Group'].map(group_sizes)\n",
    "val_x['numMembers'] = val_x['Group'].map(group_sizes)\n",
    "test_x['numMembers'] = test_x['Group'].map(group_sizes)\n",
    "\n",
    "# Display the updated dataframes\n",
    "print(\"Updated train_x:\")\n",
    "print(train_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated val_x:\")\n",
    "print(val_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated test_x:\")\n",
    "print(test_x[['PassengerId', 'Group', 'numMembers']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can remove the columns PassengerId and Group, that don't give us any more information, however I will wait and remove all the useless columns after analyze all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomePlanet \n",
    "The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "This is a categorical feature, so we will need to encode it in some way in order to give the information to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet unique values:  ['Mars' 'Europa' 'Earth' nan]\n",
      "Missing values in HomePlanet:  174 (2.22%)\n"
     ]
    }
   ],
   "source": [
    "# First I check how many different values we have in this variant (HomePlanet)\n",
    "print(\"HomePlanet unique values: \", train_x['HomePlanet'].unique())\n",
    "\n",
    "# And also if there are any missing values and how many\n",
    "print(\"Missing values in HomePlanet: \", train_x['HomePlanet'].isnull().sum(), f\"({train_x['HomePlanet'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's solve the issue with the missing values, we can assume that members of the same group depart from the same planet, so the first approach will be to assign the existing value of one member of the group to other members that have a null value in the HomePlanet variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_9096\\2562908295.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling:\n",
      "train_x: 96\n",
      "val_x: 15\n",
      "test_x: 46\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Fill missing HomePlanet values based on the group\n",
    "combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Update train_x, val_x, and test_x with the filled values from combined_df based on PassengerId\n",
    "train_x['HomePlanet'] = train_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "val_x['HomePlanet'] = val_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "test_x['HomePlanet'] = test_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling:\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0064_02</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>E/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Colatz Keen</td>\n",
       "      <td>0064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "59     0064_02       Mars      True  E/3/S  TRAPPIST-1e  33.0  False   \n",
       "\n",
       "    RoomService  FoodCourt  ShoppingMall  Spa  VRDeck         Name Group  \\\n",
       "59          0.0        0.0           NaN  0.0     0.0  Colatz Keen  0064   \n",
       "\n",
       "    numMembers  \n",
       "59           2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check an example to see that everything is correct, in this case the group 0064 come from Mars\n",
    "combined_df[combined_df['Name'] == 'Colatz Keen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filled ~50% of the empty values based on the training set, however we still have a little bit more than a 1% of empty entries, so now I will check the class distribution, maybe there is one popular class and I can simply give that class value to the empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet distribution (counts):\n",
      "HomePlanet\n",
      "Earth     4151\n",
      "Europa    1962\n",
      "Mars      1614\n",
      "NaN         96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HomePlanet distribution (percentages):\n",
      "HomePlanet\n",
      "Earth     53.06\n",
      "Europa    25.08\n",
      "Mars      20.63\n",
      "NaN        1.23\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution for the HomePlanet column\n",
    "homeplanet_distribution = train_x['HomePlanet'].value_counts(dropna=False)\n",
    "homeplanet_percentages = (train_x['HomePlanet'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"HomePlanet distribution (counts):\")\n",
    "print(homeplanet_distribution)\n",
    "print(\"\\nHomePlanet distribution (percentages):\")\n",
    "print(homeplanet_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the distribution, if I assign Earth to the empty values, I will aim ~53% of the cases, taking into account that we have 1.23% of empty values, I will have ~0.6% of incorrect values with this approach, this is a very low percentage, so I go with this plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling with 'Earth':\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the HomePlanet column with 'Earth'\n",
    "train_x['HomePlanet'] = train_x['HomePlanet'].fillna('Earth')\n",
    "val_x['HomePlanet'] = val_x['HomePlanet'].fillna('Earth')\n",
    "test_x['HomePlanet'] = test_x['HomePlanet'].fillna('Earth')\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling with 'Earth':\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to train the model with this feature, we need to encode it, to do that I will use one-hot encoding that will add 1 more variable to the problem.\n",
    "\n",
    "The idea is to pass from HomePlanet to two boolean variables, isHomeEarth and isHomeEuropa, if both variants are False we still have the info that the HomePlanet is Mars without having to explicitly saving into another variant. With this approach I am assuming that the only possible HomePlanets are Earth, Mars and Europa, which is not crazy to say seeing the class distribution in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  isHomeEarth  isHomeEuropa\n",
       "4132       Mars            0             0\n",
       "7217     Europa            0             1\n",
       "7216      Earth            1             0\n",
       "7968      Earth            1             0\n",
       "50        Earth            1             0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for HomePlanet\n",
    "train_x['isHomeEarth'] = (train_x['HomePlanet'] == 'Earth').astype(int)\n",
    "train_x['isHomeEuropa'] = (train_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "val_x['isHomeEarth'] = (val_x['HomePlanet'] == 'Earth').astype(int)\n",
    "val_x['isHomeEuropa'] = (val_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "test_x['isHomeEarth'] = (test_x['HomePlanet'] == 'Earth').astype(int)\n",
    "test_x['isHomeEuropa'] = (test_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['HomePlanet', 'isHomeEarth', 'isHomeEuropa']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CryoSleep \n",
    "Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "This is a boolean variable, so we only have to cast it into integer, however first I need to check if there are any empty value and the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep distribution (counts):\n",
      "CryoSleep\n",
      "False    4898\n",
      "True     2731\n",
      "NaN       194\n",
      "Name: count, dtype: int64\n",
      "\\CryoSleep distribution (percentages):\n",
      "CryoSleep\n",
      "False    62.61\n",
      "True     34.91\n",
      "NaN       2.48\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in CryoSleep:  194 (2.48%)\n"
     ]
    }
   ],
   "source": [
    "# Print the distribution of CryoSleep\n",
    "cryosleep_distribution = train_x['CryoSleep'].value_counts(dropna=False)\n",
    "cryosleep_percentages = (train_x['CryoSleep'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"CryoSleep distribution (counts):\")\n",
    "print(cryosleep_distribution)\n",
    "print(\"\\CryoSleep distribution (percentages):\")\n",
    "print(cryosleep_percentages)\n",
    "\n",
    "print(\"Missing values in CryoSleep: \", train_x['CryoSleep'].isnull().sum(), f\"({train_x['CryoSleep'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar than with the HomePlanet, we have ~2.5% of empty values.\n",
    "\n",
    "In this case, we have the statement where if a passenger is in cryosleep, he is confined inside his cabin, so he won't spend any money on services, that means that variables RoomService, FoodCourt, ShoppingMall, Spa and VRDeck will be all 0.\n",
    "\n",
    "To confirm this, lets check:\n",
    "* When CryoSleep == True, sum(RoomService, FoodCourt, ShoppingMall, Spa and VRDeck) == 0.0\n",
    "* When CryoSleep == False, sum(RoomService, FoodCourt, ShoppingMall, Spa and VRDeck) > 0.0\n",
    "\n",
    "To do this check I will exclude samples with any of this fields empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep == True and all services == 0.0:\n",
      "True\n",
      "Number of samples: 2413\n",
      "\n",
      "CryoSleep == False and sum of services > 0.0:\n",
      "False\n",
      "Number of samples: 4408\n",
      "\n",
      "Rows where CryoSleep == False and sum of services == 0.0:\n",
      "     PassengerId HomePlanet CryoSleep     Cabin  Destination   Age    VIP  \\\n",
      "5554     5922_01      Earth     False   G/960/P  TRAPPIST-1e  32.0  False   \n",
      "8440     9013_03      Earth     False  G/1461/P  55 Cancri e   0.0  False   \n",
      "396      0436_01      Earth     False    G/63/S  55 Cancri e  10.0  False   \n",
      "5792     6137_01      Earth     False   G/994/S  TRAPPIST-1e   2.0  False   \n",
      "2948     3195_05      Earth     False       NaN  55 Cancri e   0.0  False   \n",
      "...          ...        ...       ...       ...          ...   ...    ...   \n",
      "4305     4592_01       Mars     False   F/862/S  TRAPPIST-1e   9.0  False   \n",
      "7316     7830_04      Earth     False  G/1268/S  TRAPPIST-1e   0.0  False   \n",
      "3455     3715_03      Earth     False   G/602/P  TRAPPIST-1e   2.0  False   \n",
      "2418     2595_01       Mars     False   F/533/P  55 Cancri e   0.0  False   \n",
      "3264     3499_04      Earth     False   G/574/P  TRAPPIST-1e   0.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall  Spa  VRDeck                Name  \\\n",
      "5554          0.0        0.0           0.0  0.0     0.0      Elia Bairdyork   \n",
      "8440          0.0        0.0           0.0  0.0     0.0   Brancy Prestonard   \n",
      "396           0.0        0.0           0.0  0.0     0.0        Sallyl Hodes   \n",
      "5792          0.0        0.0           0.0  0.0     0.0        Camily Serry   \n",
      "2948          0.0        0.0           0.0  0.0     0.0     Allena Litthews   \n",
      "...           ...        ...           ...  ...     ...                 ...   \n",
      "4305          0.0        0.0           0.0  0.0     0.0        Crunch CartÃ©   \n",
      "7316          0.0        0.0           0.0  0.0     0.0       Eddiey Belley   \n",
      "3455          0.0        0.0           0.0  0.0     0.0      Vane Hubbarton   \n",
      "2418          0.0        0.0           0.0  0.0     0.0          Lies Cakie   \n",
      "3264          0.0        0.0           0.0  0.0     0.0  Allene Mccarveymon   \n",
      "\n",
      "     Group  numMembers  isHomeEarth  isHomeEuropa  \n",
      "5554  5922           1            1             0  \n",
      "8440  9013           3            1             0  \n",
      "396   0436           2            1             0  \n",
      "5792  6137           6            1             0  \n",
      "2948  3195           6            1             0  \n",
      "...    ...         ...          ...           ...  \n",
      "4305  4592           4            0             0  \n",
      "7316  7830           4            1             0  \n",
      "3455  3715           4            1             0  \n",
      "2418  2595           4            0             0  \n",
      "3264  3499           4            1             0  \n",
      "\n",
      "[422 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exclude samples with any of the relevant fields empty\n",
    "filtered_df = train_x.dropna(subset=['CryoSleep', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'])\n",
    "\n",
    "# Check the conditions\n",
    "cryosleep_true = filtered_df[filtered_df['CryoSleep'] == True]\n",
    "cryosleep_false = filtered_df[filtered_df['CryoSleep'] == False]\n",
    "\n",
    "cryosleep_true_condition = cryosleep_true[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1).eq(0.0)\n",
    "cryosleep_false_condition = cryosleep_false[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1).gt(0.0)\n",
    "\n",
    "# Print the results\n",
    "print(\"CryoSleep == True and all services == 0.0:\")\n",
    "print(cryosleep_true_condition.all())\n",
    "print(f\"Number of samples: {len(cryosleep_true)}\")\n",
    "if not cryosleep_true_condition.all():\n",
    "    print(\"\\nRows where CryoSleep == True and all services != 0.0:\")\n",
    "    print(cryosleep_true[~cryosleep_true_condition])\n",
    "\n",
    "print(\"\\nCryoSleep == False and sum of services > 0.0:\")\n",
    "print(cryosleep_false_condition.all())\n",
    "print(f\"Number of samples: {len(cryosleep_false)}\")\n",
    "if not cryosleep_false_condition.all():\n",
    "    print(\"\\nRows where CryoSleep == False and sum of services == 0.0:\")\n",
    "    print(cryosleep_false[~cryosleep_false_condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, with the obtained results we can assume that if a passenger has spent something, he is not on cryosleep, however we CANNOT assume that if a passenger didn't spend anything, he is on cryosleep.\n",
    "\n",
    "So let's do a recap, taking into account the distribution (~62.5% False -- ~35% True), the most probable is that inside that ~2.5% of empty values this distribution also apply, so let's apply the rule where if a passenger has spent something, he is not on cryosleep and see the new distribution to evaluate the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep distribution (counts):\n",
      "CryoSleep\n",
      "False    5006\n",
      "True     2731\n",
      "NaN        86\n",
      "Name: count, dtype: int64\n",
      "\\CryoSleep distribution (percentages):\n",
      "CryoSleep\n",
      "False    63.99\n",
      "True     34.91\n",
      "NaN       1.10\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in CryoSleep:  86 (1.10%)\n"
     ]
    }
   ],
   "source": [
    "# When 'CryoSleep' is nan, if a passenger has spent something on 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa' or 'VRDeck', he is not on cryosleep, so we can fill 'CryoSleep' as False\n",
    "train_x.loc[train_x['CryoSleep'].isnull() & (train_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "val_x.loc[val_x['CryoSleep'].isnull() & (val_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "test_x.loc[train_x['CryoSleep'].isnull() & (test_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "\n",
    "# Print the updated distribution of CryoSleep\n",
    "cryosleep_distribution = train_x['CryoSleep'].value_counts(dropna=False)\n",
    "cryosleep_percentages = (train_x['CryoSleep'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"CryoSleep distribution (counts):\")\n",
    "print(cryosleep_distribution)\n",
    "print(\"\\CryoSleep distribution (percentages):\")\n",
    "print(cryosleep_percentages)\n",
    "\n",
    "print(\"Missing values in CryoSleep: \", train_x['CryoSleep'].isnull().sum(), f\"({train_x['CryoSleep'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 194 NaN values and now we have only 86, meaning that from that set of 194 samples, the 55.67% of the samples are not CryoSleep and the remain percentage is still unknown, taking into account that approx. the 62.61% of the samples inside a set are not CryoSleep, there is still a 6.94% of the samples that can not be CryoSleep, this means that there are ~13 samples that are not CryoSleep, but didn't spend a penny. In total percentages this means that from the 7823 samples that the training set has, a ~0.17 of them will have this field wrong. So we can take the risk of assign CryoSleep == True to the rest of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in CryoSleep after filling with True:\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_9096\\1584031860.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_x['CryoSleep'] = train_x['CryoSleep'].fillna(True)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_9096\\1584031860.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_x['CryoSleep'] = val_x['CryoSleep'].fillna(True)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_9096\\1584031860.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_x['CryoSleep'] = test_x['CryoSleep'].fillna(True)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the CryoSleep column with True\n",
    "train_x['CryoSleep'] = train_x['CryoSleep'].fillna(True)\n",
    "val_x['CryoSleep'] = val_x['CryoSleep'].fillna(True)\n",
    "test_x['CryoSleep'] = test_x['CryoSleep'].fillna(True)\n",
    "\n",
    "# Verify if there are still missing values in CryoSleep\n",
    "print(\"Missing values in CryoSleep after filling with True:\")\n",
    "print(f\"train_x: {train_x['CryoSleep'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['CryoSleep'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['CryoSleep'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cast the boolean values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>4408_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>1</td>\n",
       "      <td>F/906/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pich Knike</td>\n",
       "      <td>4408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7710_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>B/253/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>Chabih Eguing</td>\n",
       "      <td>7710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>7709_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>G/1238/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Sweett</td>\n",
       "      <td>7709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>8512_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F/1637/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Verly Flyncharlan</td>\n",
       "      <td>8512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0052_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>G/6/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elaney Hubbarton</td>\n",
       "      <td>0052</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4132     4408_01       Mars          1   F/906/P    TRAPPIST-1e  75.0  False   \n",
       "7217     7710_01     Europa          0   B/253/P    TRAPPIST-1e  27.0  False   \n",
       "7216     7709_02      Earth          1  G/1238/P  PSO J318.5-22  24.0  False   \n",
       "7968     8512_01      Earth          0  F/1637/S    55 Cancri e  48.0  False   \n",
       "50       0052_01      Earth          0     G/6/S    TRAPPIST-1e   NaN  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "4132          0.0        0.0           0.0     0.0     0.0         Pich Knike   \n",
       "7217        118.0     1769.0        4127.0   118.0   619.0      Chabih Eguing   \n",
       "7216          0.0        NaN           0.0     0.0     0.0      Lerome Sweett   \n",
       "7968          0.0      717.0           0.0     0.0    10.0  Verly Flyncharlan   \n",
       "50            4.0        0.0           2.0  4683.0     0.0   Elaney Hubbarton   \n",
       "\n",
       "     Group  numMembers  isHomeEarth  isHomeEuropa  \n",
       "4132  4408           1            0             0  \n",
       "7217  7710           1            0             1  \n",
       "7216  7709           2            1             0  \n",
       "7968  8512           1            1             0  \n",
       "50    0052           1            1             0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['CryoSleep'] = train_x['CryoSleep'].astype(int)\n",
    "val_x['CryoSleep'] = val_x['CryoSleep'].astype(int)\n",
    "test_x['CryoSleep'] = test_x['CryoSleep'].astype(int)\n",
    "\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin\n",
    "The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
