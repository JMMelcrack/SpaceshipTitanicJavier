{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic\n",
    "\n",
    "Our goal is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and Data Field Descriptions\n",
    "\n",
    "* **train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    * PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "    * HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    * CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    * Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    * Destination - The planet the passenger will be debarking to.\n",
    "    * Age - The age of the passenger.\n",
    "    * VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    * RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    * Name - The first and last names of the passenger.\n",
    "    * Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "* **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "* **sample_submission.csv** - A submission file in the correct format.\n",
    "    * PassengerId - Id for each passenger in the test set.\n",
    "    * Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T22:51:46.329307Z",
     "iopub.status.busy": "2025-04-17T22:51:46.328988Z",
     "iopub.status.idle": "2025-04-17T22:51:46.334775Z",
     "shell.execute_reply": "2025-04-17T22:51:46.333736Z",
     "shell.execute_reply.started": "2025-04-17T22:51:46.329278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset loading and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T22:53:41.701025Z",
     "iopub.status.busy": "2025-04-17T22:53:41.700621Z",
     "iopub.status.idle": "2025-04-17T22:53:41.799405Z",
     "shell.execute_reply": "2025-04-17T22:53:41.798601Z",
     "shell.execute_reply.started": "2025-04-17T22:53:41.701001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (8693, 14)\n",
      "Full test dataset shape is (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset into a Pandas Dataframe\n",
    "# Try to load the dataset from Kaggle, if not found, load from local directory\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.read_csv('kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('kaggle/input/spaceship-titanic/test.csv')\n",
    "\n",
    "print(\"Full train dataset shape is {}\".format(train_df.shape))\n",
    "print(\"Full test dataset shape is {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# I split the datasets into features (X) and tag (Y)\n",
    "train_x = train_df.drop(columns=['Transported'])\n",
    "train_y = train_df['Transported'].astype(int)  # Convert boolean to int (0 or 1)\n",
    "\n",
    "test_x = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the different models used, I split the training set into train and validation, giving a 10% of the samples to the validation set. I set that percentage in order to have a dataset big enough to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>4408_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/906/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pich Knike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7710_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/253/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>Chabih Eguing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>7709_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1238/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Sweett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>8512_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1637/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Verly Flyncharlan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0052_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/6/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elaney Hubbarton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4132     4408_01       Mars      True   F/906/P    TRAPPIST-1e  75.0  False   \n",
       "7217     7710_01     Europa     False   B/253/P    TRAPPIST-1e  27.0  False   \n",
       "7216     7709_02      Earth      True  G/1238/P  PSO J318.5-22  24.0  False   \n",
       "7968     8512_01      Earth     False  F/1637/S    55 Cancri e  48.0  False   \n",
       "50       0052_01      Earth     False     G/6/S    TRAPPIST-1e   NaN  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "4132          0.0        0.0           0.0     0.0     0.0         Pich Knike  \n",
       "7217        118.0     1769.0        4127.0   118.0   619.0      Chabih Eguing  \n",
       "7216          0.0        NaN           0.0     0.0     0.0      Lerome Sweett  \n",
       "7968          0.0      717.0           0.0     0.0    10.0  Verly Flyncharlan  \n",
       "50            4.0        0.0           2.0  4683.0     0.0   Elaney Hubbarton  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state=0)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After separate a validation set from our training set, the next step is to preprocess the dataset, to do that I will check each individual feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId\n",
    "\n",
    "This variable represents a unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "At the begining it seems to be a variant without information to solve the problem, something like a name, however as it said, we can extract the number of members that each group has and that can be something relevant.\n",
    "However to know the number of members a group has, we have to use the whole dataset, trining + validation + test sets. To do this would be a problem in most cases because we are not sure that our dataset contain all the existent samples, however for this task, the description tells us that we have about two-thirds (~8700) of the passengers as the training set and THE REMAINING one-third (~4300) of the passengers as test, so we got at least partial information about all the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in PassengerId:\n",
      "train_x: 0\n",
      "test_x: 0\n",
      "val_x: 0\n",
      "Updated train_x:\n",
      "     PassengerId Group  numMembers\n",
      "4132     4408_01  4408           1\n",
      "7217     7710_01  7710           1\n",
      "7216     7709_02  7709           2\n",
      "7968     8512_01  8512           1\n",
      "50       0052_01  0052           1\n",
      "\n",
      "Updated val_x:\n",
      "     PassengerId Group  numMembers\n",
      "3601     3868_05  3868           7\n",
      "6057     6405_02  6405           4\n",
      "2797     3021_01  3021           2\n",
      "7110     7578_01  7578           1\n",
      "8579     9158_01  9158           1\n",
      "\n",
      "Updated test_x:\n",
      "  PassengerId Group  numMembers\n",
      "0     0013_01  0013           1\n",
      "1     0018_01  0018           1\n",
      "2     0019_01  0019           1\n",
      "3     0021_01  0021           1\n",
      "4     0023_01  0023           1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in PassengerId\n",
    "print(\"Missing values in PassengerId:\")\n",
    "print(f\"train_x: {train_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['PassengerId'].isnull().sum()}\")\n",
    "\n",
    "# Extract group identifier (gggg) from PassengerId\n",
    "train_x['Group'] = train_x['PassengerId'].str.split('_').str[0]\n",
    "test_x['Group'] = test_x['PassengerId'].str.split('_').str[0]\n",
    "val_x['Group'] = val_x['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "# Combine all dataframes to calculate group sizes across all datasets\n",
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Calculate the total number of members in each group\n",
    "group_sizes = combined_df['Group'].value_counts()\n",
    "\n",
    "# Add the numMembers column to each dataframe\n",
    "train_x['numMembers'] = train_x['Group'].map(group_sizes)\n",
    "val_x['numMembers'] = val_x['Group'].map(group_sizes)\n",
    "test_x['numMembers'] = test_x['Group'].map(group_sizes)\n",
    "\n",
    "# Display the updated dataframes\n",
    "print(\"Updated train_x:\")\n",
    "print(train_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated val_x:\")\n",
    "print(val_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated test_x:\")\n",
    "print(test_x[['PassengerId', 'Group', 'numMembers']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can remove the columns PassengerId and Group, that don't give us any more information, however I will wait and remove all the useless columns after analyze all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomePlanet \n",
    "The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "This is a categorical feature, so we will need to encode it in some way in order to give the information to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet unique values:  ['Mars' 'Europa' 'Earth' nan]\n",
      "Missing values in HomePlanet:  174 (2.22%)\n"
     ]
    }
   ],
   "source": [
    "# First I check how many different values we have in this variant (HomePlanet)\n",
    "print(\"HomePlanet unique values: \", train_x['HomePlanet'].unique())\n",
    "\n",
    "# And also if there are any missing values and how many\n",
    "print(\"Missing values in HomePlanet: \", train_x['HomePlanet'].isnull().sum(), f\"({train_x['HomePlanet'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's solve the issue with the missing values, we can assume that members of the same group depart from the same planet, so the first approach will be to assign the existing value of one member of the group to other members that have a null value in the HomePlanet variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_21468\\2562908295.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling:\n",
      "train_x: 96\n",
      "val_x: 15\n",
      "test_x: 46\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Fill missing HomePlanet values based on the group\n",
    "combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Update train_x, val_x, and test_x with the filled values from combined_df based on PassengerId\n",
    "train_x['HomePlanet'] = train_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "val_x['HomePlanet'] = val_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "test_x['HomePlanet'] = test_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling:\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0064_02</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>E/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Colatz Keen</td>\n",
       "      <td>0064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "59     0064_02       Mars      True  E/3/S  TRAPPIST-1e  33.0  False   \n",
       "\n",
       "    RoomService  FoodCourt  ShoppingMall  Spa  VRDeck         Name Group  \\\n",
       "59          0.0        0.0           NaN  0.0     0.0  Colatz Keen  0064   \n",
       "\n",
       "    numMembers  \n",
       "59           2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check an example to see that everything is correct, in this case the group 0064 come from Mars\n",
    "combined_df[combined_df['Name'] == 'Colatz Keen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filled ~50% of the empty values based on the training set, however we still have a little bit more than a 1% of empty entries, so now I will check the class distribution, maybe there is one popular class and I can simply give that class value to the empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet distribution (counts):\n",
      "HomePlanet\n",
      "Earth     4151\n",
      "Europa    1962\n",
      "Mars      1614\n",
      "NaN         96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HomePlanet distribution (percentages):\n",
      "HomePlanet\n",
      "Earth     53.06\n",
      "Europa    25.08\n",
      "Mars      20.63\n",
      "NaN        1.23\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution for the HomePlanet column\n",
    "homeplanet_distribution = train_x['HomePlanet'].value_counts(dropna=False)\n",
    "homeplanet_percentages = (train_x['HomePlanet'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"HomePlanet distribution (counts):\")\n",
    "print(homeplanet_distribution)\n",
    "print(\"\\nHomePlanet distribution (percentages):\")\n",
    "print(homeplanet_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the distribution, if I assign Earth to the empty values, I will aim ~53% of the cases, taking into account that we have 1.23% of empty values, I will have ~0.6% of incorrect values with this approach, this is a very low percentage, so I go with this plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling with 'Earth':\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the HomePlanet column with 'Earth'\n",
    "train_x['HomePlanet'] = train_x['HomePlanet'].fillna('Earth')\n",
    "val_x['HomePlanet'] = val_x['HomePlanet'].fillna('Earth')\n",
    "test_x['HomePlanet'] = test_x['HomePlanet'].fillna('Earth')\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling with 'Earth':\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to train the model with this feature, we need to encode it, to do that I will use one-hot encoding that will add 1 more variable to the problem.\n",
    "\n",
    "The idea is to pass from HomePlanet to two boolean variables, isHomeEarth and isHomeEuropa, if both variants are False we still have the info that the HomePlanet is Mars without having to explicitly saving into another variant. With this approach I am assuming that the only possible HomePlanets are Earth, Mars and Europa, which is not crazy to say seeing the class distribution in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  isHomeEarth  isHomeEuropa\n",
       "4132       Mars            0             0\n",
       "7217     Europa            0             1\n",
       "7216      Earth            1             0\n",
       "7968      Earth            1             0\n",
       "50        Earth            1             0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for HomePlanet\n",
    "train_x['isHomeEarth'] = (train_x['HomePlanet'] == 'Earth').astype(int)\n",
    "train_x['isHomeEuropa'] = (train_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "val_x['isHomeEarth'] = (val_x['HomePlanet'] == 'Earth').astype(int)\n",
    "val_x['isHomeEuropa'] = (val_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "test_x['isHomeEarth'] = (test_x['HomePlanet'] == 'Earth').astype(int)\n",
    "test_x['isHomeEuropa'] = (test_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['HomePlanet', 'isHomeEarth', 'isHomeEuropa']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CryoSleep \n",
    "Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "This is a boolean variable, so we only have to cast it into integer, however first I need to check if there are any empty value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
