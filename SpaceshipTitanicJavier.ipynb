{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic\n",
    "\n",
    "Our goal is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and Data Field Descriptions\n",
    "\n",
    "* **train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    * PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "    * HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    * CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    * Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    * Destination - The planet the passenger will be debarking to.\n",
    "    * Age - The age of the passenger.\n",
    "    * VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    * RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    * Name - The first and last names of the passenger.\n",
    "    * Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "* **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "* **sample_submission.csv** - A submission file in the correct format.\n",
    "    * PassengerId - Id for each passenger in the test set.\n",
    "    * Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T22:51:46.329307Z",
     "iopub.status.busy": "2025-04-17T22:51:46.328988Z",
     "iopub.status.idle": "2025-04-17T22:51:46.334775Z",
     "shell.execute_reply": "2025-04-17T22:51:46.333736Z",
     "shell.execute_reply.started": "2025-04-17T22:51:46.329278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset loading and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T22:53:41.701025Z",
     "iopub.status.busy": "2025-04-17T22:53:41.700621Z",
     "iopub.status.idle": "2025-04-17T22:53:41.799405Z",
     "shell.execute_reply": "2025-04-17T22:53:41.798601Z",
     "shell.execute_reply.started": "2025-04-17T22:53:41.701001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (8693, 14)\n",
      "Full test dataset shape is (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset into a Pandas Dataframe\n",
    "# Try to load the dataset from Kaggle, if not found, load from local directory\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.read_csv('kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('kaggle/input/spaceship-titanic/test.csv')\n",
    "\n",
    "print(\"Full train dataset shape is {}\".format(train_df.shape))\n",
    "print(\"Full test dataset shape is {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# I split the datasets into features (X) and tag (Y)\n",
    "train_x = train_df.drop(columns=['Transported'])\n",
    "train_y = train_df['Transported'].astype(int)  # Convert boolean to int (0 or 1)\n",
    "\n",
    "test_x = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the different models used, I split the training set into train and validation, giving a 10% of the samples to the validation set. I set that percentage in order to have a dataset big enough to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape is (7823, 13)\n",
      "Validation dataset shape is (870, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>4408_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/906/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pich Knike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7710_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/253/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>Chabih Eguing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>7709_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1238/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Sweett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>8512_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1637/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Verly Flyncharlan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0052_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/6/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elaney Hubbarton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4132     4408_01       Mars      True   F/906/P    TRAPPIST-1e  75.0  False   \n",
       "7217     7710_01     Europa     False   B/253/P    TRAPPIST-1e  27.0  False   \n",
       "7216     7709_02      Earth      True  G/1238/P  PSO J318.5-22  24.0  False   \n",
       "7968     8512_01      Earth     False  F/1637/S    55 Cancri e  48.0  False   \n",
       "50       0052_01      Earth     False     G/6/S    TRAPPIST-1e   NaN  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "4132          0.0        0.0           0.0     0.0     0.0         Pich Knike  \n",
       "7217        118.0     1769.0        4127.0   118.0   619.0      Chabih Eguing  \n",
       "7216          0.0        NaN           0.0     0.0     0.0      Lerome Sweett  \n",
       "7968          0.0      717.0           0.0     0.0    10.0  Verly Flyncharlan  \n",
       "50            4.0        0.0           2.0  4683.0     0.0   Elaney Hubbarton  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(\"Train dataset shape is {}\".format(train_x.shape))\n",
    "print(\"Validation dataset shape is {}\".format(val_x.shape))\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After separate a validation set from our training set, the next step is to preprocess the dataset, to do that I will check each individual feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId\n",
    "\n",
    "This variable represents a unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "At the begining it seems to be a variant without information to solve the problem, something like a name, however as it said, we can extract the number of members that each group has and that can be something relevant.\n",
    "However to know the number of members a group has, we have to use the whole dataset, trining + validation + test sets. To do this would be a problem in most cases because we are not sure that our dataset contain all the existent samples, however for this task, the description tells us that we have about two-thirds (~8700) of the passengers as the training set and THE REMAINING one-third (~4300) of the passengers as test, so we got at least partial information about all the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in PassengerId:\n",
      "train_x: 0\n",
      "test_x: 0\n",
      "val_x: 0\n",
      "Updated train_x:\n",
      "     PassengerId Group  numMembers\n",
      "4132     4408_01  4408           1\n",
      "7217     7710_01  7710           1\n",
      "7216     7709_02  7709           2\n",
      "7968     8512_01  8512           1\n",
      "50       0052_01  0052           1\n",
      "\n",
      "Updated val_x:\n",
      "     PassengerId Group  numMembers\n",
      "3601     3868_05  3868           7\n",
      "6057     6405_02  6405           4\n",
      "2797     3021_01  3021           2\n",
      "7110     7578_01  7578           1\n",
      "8579     9158_01  9158           1\n",
      "\n",
      "Updated test_x:\n",
      "  PassengerId Group  numMembers\n",
      "0     0013_01  0013           1\n",
      "1     0018_01  0018           1\n",
      "2     0019_01  0019           1\n",
      "3     0021_01  0021           1\n",
      "4     0023_01  0023           1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in PassengerId\n",
    "print(\"Missing values in PassengerId:\")\n",
    "print(f\"train_x: {train_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['PassengerId'].isnull().sum()}\")\n",
    "\n",
    "# Extract group identifier (gggg) from PassengerId\n",
    "train_x['Group'] = train_x['PassengerId'].str.split('_').str[0]\n",
    "test_x['Group'] = test_x['PassengerId'].str.split('_').str[0]\n",
    "val_x['Group'] = val_x['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "# Combine all dataframes to calculate group sizes across all datasets\n",
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Calculate the total number of members in each group\n",
    "group_sizes = combined_df['Group'].value_counts()\n",
    "\n",
    "# Add the numMembers column to each dataframe\n",
    "train_x['numMembers'] = train_x['Group'].map(group_sizes)\n",
    "val_x['numMembers'] = val_x['Group'].map(group_sizes)\n",
    "test_x['numMembers'] = test_x['Group'].map(group_sizes)\n",
    "\n",
    "# Display the updated dataframes\n",
    "print(\"Updated train_x:\")\n",
    "print(train_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated val_x:\")\n",
    "print(val_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated test_x:\")\n",
    "print(test_x[['PassengerId', 'Group', 'numMembers']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can remove the columns PassengerId and Group, that don't give us any more information, however I will wait and remove all the useless columns after analyze all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomePlanet \n",
    "The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "This is a categorical feature, so we will need to encode it in some way in order to give the information to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet unique values:  ['Mars' 'Europa' 'Earth' nan]\n",
      "Missing values in HomePlanet:  174 (2.22%)\n"
     ]
    }
   ],
   "source": [
    "# First I check how many different values we have in this variant (HomePlanet)\n",
    "print(\"HomePlanet unique values: \", train_x['HomePlanet'].unique())\n",
    "\n",
    "# And also if there are any missing values and how many\n",
    "print(\"Missing values in HomePlanet: \", train_x['HomePlanet'].isnull().sum(), f\"({train_x['HomePlanet'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's solve the issue with the missing values, we can assume that members of the same group depart from the same planet, so the first approach will be to assign the existing value of one member of the group to other members that have a null value in the HomePlanet variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All members of the same group have the same HomePlanet.\n"
     ]
    }
   ],
   "source": [
    "# Check if all members of the same group have the same HomePlanet\n",
    "group_destination_check = train_x.groupby('Group')['HomePlanet'].nunique()\n",
    "\n",
    "# Find groups with more than one unique HomePlanet\n",
    "inconsistent_groups = group_destination_check[group_destination_check > 1]\n",
    "\n",
    "# Print the result\n",
    "if inconsistent_groups.empty:\n",
    "    print(\"All members of the same group have the same HomePlanet.\")\n",
    "else:\n",
    "    print(\"Some groups have inconsistent HomePlanet:\")\n",
    "    print(inconsistent_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\2562908295.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling:\n",
      "train_x: 96\n",
      "val_x: 15\n",
      "test_x: 46\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Fill missing HomePlanet values based on the group\n",
    "combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Update train_x, val_x, and test_x with the filled values from combined_df based on PassengerId\n",
    "train_x['HomePlanet'] = train_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "val_x['HomePlanet'] = val_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "test_x['HomePlanet'] = test_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling:\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0064_02</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>E/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Colatz Keen</td>\n",
       "      <td>0064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "59     0064_02       Mars      True  E/3/S  TRAPPIST-1e  33.0  False   \n",
       "\n",
       "    RoomService  FoodCourt  ShoppingMall  Spa  VRDeck         Name Group  \\\n",
       "59          0.0        0.0           NaN  0.0     0.0  Colatz Keen  0064   \n",
       "\n",
       "    numMembers  \n",
       "59           2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check an example to see that everything is correct, in this case the group 0064 come from Mars\n",
    "combined_df[combined_df['Name'] == 'Colatz Keen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filled ~50% of the empty values based on the training set, however we still have a little bit more than a 1% of empty entries, so now I will check the class distribution, maybe there is one popular class and I can simply give that class value to the empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet distribution (counts):\n",
      "HomePlanet\n",
      "Earth     4151\n",
      "Europa    1962\n",
      "Mars      1614\n",
      "NaN         96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HomePlanet distribution (percentages):\n",
      "HomePlanet\n",
      "Earth     53.06\n",
      "Europa    25.08\n",
      "Mars      20.63\n",
      "NaN        1.23\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution for the HomePlanet column\n",
    "homeplanet_distribution = train_x['HomePlanet'].value_counts(dropna=False)\n",
    "homeplanet_percentages = (train_x['HomePlanet'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"HomePlanet distribution (counts):\")\n",
    "print(homeplanet_distribution)\n",
    "print(\"\\nHomePlanet distribution (percentages):\")\n",
    "print(homeplanet_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the distribution, if I assign Earth to the empty values, I will aim ~53% of the cases, taking into account that we have 1.23% of empty values, I will have ~0.6% of incorrect values with this approach, this is a very low percentage, so I go with this plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling with 'Earth':\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the HomePlanet column with 'Earth'\n",
    "train_x['HomePlanet'] = train_x['HomePlanet'].fillna('Earth')\n",
    "val_x['HomePlanet'] = val_x['HomePlanet'].fillna('Earth')\n",
    "test_x['HomePlanet'] = test_x['HomePlanet'].fillna('Earth')\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling with 'Earth':\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to train the model with this feature, we need to encode it, to do that I will use one-hot encoding that will add 1 more variable to the problem.\n",
    "\n",
    "The idea is to pass from HomePlanet to two boolean variables, isHomeEarth and isHomeEuropa, if both variants are False we still have the info that the HomePlanet is Mars without having to explicitly saving into another variant. With this approach I am assuming that the only possible HomePlanets are Earth, Mars and Europa, which is not crazy to say seeing the class distribution in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  isHomeEarth  isHomeEuropa\n",
       "4132       Mars            0             0\n",
       "7217     Europa            0             1\n",
       "7216      Earth            1             0\n",
       "7968      Earth            1             0\n",
       "50        Earth            1             0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for HomePlanet\n",
    "train_x['isHomeEarth'] = (train_x['HomePlanet'] == 'Earth').astype(int)\n",
    "train_x['isHomeEuropa'] = (train_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "val_x['isHomeEarth'] = (val_x['HomePlanet'] == 'Earth').astype(int)\n",
    "val_x['isHomeEuropa'] = (val_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "test_x['isHomeEarth'] = (test_x['HomePlanet'] == 'Earth').astype(int)\n",
    "test_x['isHomeEuropa'] = (test_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['HomePlanet', 'isHomeEarth', 'isHomeEuropa']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CryoSleep \n",
    "Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "This is a boolean variable, so we only have to cast it into integer, however first I need to check if there are any empty value and the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep distribution (counts):\n",
      "CryoSleep\n",
      "False    4898\n",
      "True     2731\n",
      "NaN       194\n",
      "Name: count, dtype: int64\n",
      "\\CryoSleep distribution (percentages):\n",
      "CryoSleep\n",
      "False    62.61\n",
      "True     34.91\n",
      "NaN       2.48\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in CryoSleep:  194 (2.48%)\n"
     ]
    }
   ],
   "source": [
    "# Print the distribution of CryoSleep\n",
    "cryosleep_distribution = train_x['CryoSleep'].value_counts(dropna=False)\n",
    "cryosleep_percentages = (train_x['CryoSleep'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"CryoSleep distribution (counts):\")\n",
    "print(cryosleep_distribution)\n",
    "print(\"\\nCryoSleep distribution (percentages):\")\n",
    "print(cryosleep_percentages)\n",
    "\n",
    "print(\"Missing values in CryoSleep: \", train_x['CryoSleep'].isnull().sum(), f\"({train_x['CryoSleep'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar than with the HomePlanet, we have ~2.5% of empty values.\n",
    "\n",
    "In this case, we have the statement where if a passenger is in cryosleep, he is confined inside his cabin, so he won't spend any money on services, that means that variables RoomService, FoodCourt, ShoppingMall, Spa and VRDeck will be all 0.\n",
    "\n",
    "To confirm this, lets check:\n",
    "* When CryoSleep == True, sum(RoomService, FoodCourt, ShoppingMall, Spa and VRDeck) == 0.0\n",
    "* When CryoSleep == False, sum(RoomService, FoodCourt, ShoppingMall, Spa and VRDeck) > 0.0\n",
    "\n",
    "To do this check I will exclude samples with any of this fields empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep == True and all services == 0.0:\n",
      "True\n",
      "Number of samples: 2413\n",
      "\n",
      "CryoSleep == False and sum of services > 0.0:\n",
      "False\n",
      "Number of samples: 4408\n",
      "\n",
      "Rows where CryoSleep == False and sum of services == 0.0:\n",
      "     PassengerId HomePlanet CryoSleep     Cabin  Destination   Age    VIP  \\\n",
      "5554     5922_01      Earth     False   G/960/P  TRAPPIST-1e  32.0  False   \n",
      "8440     9013_03      Earth     False  G/1461/P  55 Cancri e   0.0  False   \n",
      "396      0436_01      Earth     False    G/63/S  55 Cancri e  10.0  False   \n",
      "5792     6137_01      Earth     False   G/994/S  TRAPPIST-1e   2.0  False   \n",
      "2948     3195_05      Earth     False       NaN  55 Cancri e   0.0  False   \n",
      "...          ...        ...       ...       ...          ...   ...    ...   \n",
      "4305     4592_01       Mars     False   F/862/S  TRAPPIST-1e   9.0  False   \n",
      "7316     7830_04      Earth     False  G/1268/S  TRAPPIST-1e   0.0  False   \n",
      "3455     3715_03      Earth     False   G/602/P  TRAPPIST-1e   2.0  False   \n",
      "2418     2595_01       Mars     False   F/533/P  55 Cancri e   0.0  False   \n",
      "3264     3499_04      Earth     False   G/574/P  TRAPPIST-1e   0.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall  Spa  VRDeck                Name  \\\n",
      "5554          0.0        0.0           0.0  0.0     0.0      Elia Bairdyork   \n",
      "8440          0.0        0.0           0.0  0.0     0.0   Brancy Prestonard   \n",
      "396           0.0        0.0           0.0  0.0     0.0        Sallyl Hodes   \n",
      "5792          0.0        0.0           0.0  0.0     0.0        Camily Serry   \n",
      "2948          0.0        0.0           0.0  0.0     0.0     Allena Litthews   \n",
      "...           ...        ...           ...  ...     ...                 ...   \n",
      "4305          0.0        0.0           0.0  0.0     0.0        Crunch Carté   \n",
      "7316          0.0        0.0           0.0  0.0     0.0       Eddiey Belley   \n",
      "3455          0.0        0.0           0.0  0.0     0.0      Vane Hubbarton   \n",
      "2418          0.0        0.0           0.0  0.0     0.0          Lies Cakie   \n",
      "3264          0.0        0.0           0.0  0.0     0.0  Allene Mccarveymon   \n",
      "\n",
      "     Group  numMembers  isHomeEarth  isHomeEuropa  \n",
      "5554  5922           1            1             0  \n",
      "8440  9013           3            1             0  \n",
      "396   0436           2            1             0  \n",
      "5792  6137           6            1             0  \n",
      "2948  3195           6            1             0  \n",
      "...    ...         ...          ...           ...  \n",
      "4305  4592           4            0             0  \n",
      "7316  7830           4            1             0  \n",
      "3455  3715           4            1             0  \n",
      "2418  2595           4            0             0  \n",
      "3264  3499           4            1             0  \n",
      "\n",
      "[422 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exclude samples with any of the relevant fields empty\n",
    "filtered_df = train_x.dropna(subset=['CryoSleep', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'])\n",
    "\n",
    "# Check the conditions\n",
    "cryosleep_true = filtered_df[filtered_df['CryoSleep'] == True]\n",
    "cryosleep_false = filtered_df[filtered_df['CryoSleep'] == False]\n",
    "\n",
    "cryosleep_true_condition = cryosleep_true[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1).eq(0.0)\n",
    "cryosleep_false_condition = cryosleep_false[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1).gt(0.0)\n",
    "\n",
    "# Print the results\n",
    "print(\"CryoSleep == True and all services == 0.0:\")\n",
    "print(cryosleep_true_condition.all())\n",
    "print(f\"Number of samples: {len(cryosleep_true)}\")\n",
    "if not cryosleep_true_condition.all():\n",
    "    print(\"\\nRows where CryoSleep == True and all services != 0.0:\")\n",
    "    print(cryosleep_true[~cryosleep_true_condition])\n",
    "\n",
    "print(\"\\nCryoSleep == False and sum of services > 0.0:\")\n",
    "print(cryosleep_false_condition.all())\n",
    "print(f\"Number of samples: {len(cryosleep_false)}\")\n",
    "if not cryosleep_false_condition.all():\n",
    "    print(\"\\nRows where CryoSleep == False and sum of services == 0.0:\")\n",
    "    print(cryosleep_false[~cryosleep_false_condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, with the obtained results we can assume that if a passenger has spent something, he is not on cryosleep, however we CANNOT assume that if a passenger didn't spend anything, he is on cryosleep.\n",
    "\n",
    "So let's do a recap, taking into account the distribution (~62.5% False -- ~35% True), the most probable is that inside that ~2.5% of empty values this distribution also apply, so let's apply the rule where if a passenger has spent something, he is not on cryosleep and see the new distribution to evaluate the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep distribution (counts):\n",
      "CryoSleep\n",
      "False    5006\n",
      "True     2731\n",
      "NaN        86\n",
      "Name: count, dtype: int64\n",
      "\\CryoSleep distribution (percentages):\n",
      "CryoSleep\n",
      "False    63.99\n",
      "True     34.91\n",
      "NaN       1.10\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in CryoSleep:  86 (1.10%)\n"
     ]
    }
   ],
   "source": [
    "# When 'CryoSleep' is nan, if a passenger has spent something on 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa' or 'VRDeck', he is not on cryosleep, so we can fill 'CryoSleep' as False\n",
    "train_x.loc[train_x['CryoSleep'].isnull() & (train_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "val_x.loc[val_x['CryoSleep'].isnull() & (val_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "test_x.loc[train_x['CryoSleep'].isnull() & (test_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "\n",
    "# Print the updated distribution of CryoSleep\n",
    "cryosleep_distribution = train_x['CryoSleep'].value_counts(dropna=False)\n",
    "cryosleep_percentages = (train_x['CryoSleep'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"CryoSleep distribution (counts):\")\n",
    "print(cryosleep_distribution)\n",
    "print(\"\\CryoSleep distribution (percentages):\")\n",
    "print(cryosleep_percentages)\n",
    "\n",
    "print(\"Missing values in CryoSleep: \", train_x['CryoSleep'].isnull().sum(), f\"({train_x['CryoSleep'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 194 NaN values and now we have only 86, meaning that from that set of 194 samples, the 55.67% of the samples are not CryoSleep and the remain percentage is still unknown, taking into account that approx. the 62.61% of the samples inside a set are not CryoSleep, there is still a 6.94% of the samples that can not be CryoSleep, this means that there are ~13 samples that are not CryoSleep, but didn't spend a penny. In total percentages this means that from the 7823 samples that the training set has, a ~0.17% of them will have this field wrong. So we can take the risk of assign CryoSleep == True to the rest of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in CryoSleep after filling with True:\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\1584031860.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_x['CryoSleep'] = train_x['CryoSleep'].fillna(True)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\1584031860.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_x['CryoSleep'] = val_x['CryoSleep'].fillna(True)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\1584031860.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_x['CryoSleep'] = test_x['CryoSleep'].fillna(True)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the CryoSleep column with True\n",
    "train_x['CryoSleep'] = train_x['CryoSleep'].fillna(True)\n",
    "val_x['CryoSleep'] = val_x['CryoSleep'].fillna(True)\n",
    "test_x['CryoSleep'] = test_x['CryoSleep'].fillna(True)\n",
    "\n",
    "# Verify if there are still missing values in CryoSleep\n",
    "print(\"Missing values in CryoSleep after filling with True:\")\n",
    "print(f\"train_x: {train_x['CryoSleep'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['CryoSleep'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['CryoSleep'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cast the boolean values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>4408_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>1</td>\n",
       "      <td>F/906/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pich Knike</td>\n",
       "      <td>4408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7710_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>B/253/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>Chabih Eguing</td>\n",
       "      <td>7710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>7709_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>G/1238/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Sweett</td>\n",
       "      <td>7709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>8512_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F/1637/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Verly Flyncharlan</td>\n",
       "      <td>8512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0052_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>G/6/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elaney Hubbarton</td>\n",
       "      <td>0052</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4132     4408_01       Mars          1   F/906/P    TRAPPIST-1e  75.0  False   \n",
       "7217     7710_01     Europa          0   B/253/P    TRAPPIST-1e  27.0  False   \n",
       "7216     7709_02      Earth          1  G/1238/P  PSO J318.5-22  24.0  False   \n",
       "7968     8512_01      Earth          0  F/1637/S    55 Cancri e  48.0  False   \n",
       "50       0052_01      Earth          0     G/6/S    TRAPPIST-1e   NaN  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "4132          0.0        0.0           0.0     0.0     0.0         Pich Knike   \n",
       "7217        118.0     1769.0        4127.0   118.0   619.0      Chabih Eguing   \n",
       "7216          0.0        NaN           0.0     0.0     0.0      Lerome Sweett   \n",
       "7968          0.0      717.0           0.0     0.0    10.0  Verly Flyncharlan   \n",
       "50            4.0        0.0           2.0  4683.0     0.0   Elaney Hubbarton   \n",
       "\n",
       "     Group  numMembers  isHomeEarth  isHomeEuropa  \n",
       "4132  4408           1            0             0  \n",
       "7217  7710           1            0             1  \n",
       "7216  7709           2            1             0  \n",
       "7968  8512           1            1             0  \n",
       "50    0052           1            1             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['CryoSleep'] = train_x['CryoSleep'].astype(int)\n",
    "val_x['CryoSleep'] = val_x['CryoSleep'].astype(int)\n",
    "test_x['CryoSleep'] = test_x['CryoSleep'].astype(int)\n",
    "\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin\n",
    "The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard. So first let's separate each value and save them in different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>F/906/P</td>\n",
       "      <td>F</td>\n",
       "      <td>906</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>B/253/P</td>\n",
       "      <td>B</td>\n",
       "      <td>253</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>G/1238/P</td>\n",
       "      <td>G</td>\n",
       "      <td>1238</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>F/1637/S</td>\n",
       "      <td>F</td>\n",
       "      <td>1637</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>G/6/S</td>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cabin CabinDeck  CabinNum CabinSide\n",
       "4132   F/906/P         F       906         P\n",
       "7217   B/253/P         B       253         P\n",
       "7216  G/1238/P         G      1238         P\n",
       "7968  F/1637/S         F      1637         S\n",
       "50       G/6/S         G         6         S"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the Cabin column into deck, num, and side\n",
    "train_x[['CabinDeck', 'CabinNum', 'CabinSide']] = train_x['Cabin'].str.split('/', expand=True)\n",
    "val_x[['CabinDeck', 'CabinNum', 'CabinSide']] = val_x['Cabin'].str.split('/', expand=True)\n",
    "test_x[['CabinDeck', 'CabinNum', 'CabinSide']] = test_x['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Convert CabinNum to numeric for potential numerical analysis\n",
    "train_x['CabinNum'] = pd.to_numeric(train_x['CabinNum'], errors='coerce').astype('Int64')\n",
    "val_x['CabinNum'] = pd.to_numeric(val_x['CabinNum'], errors='coerce').astype('Int64')\n",
    "test_x['CabinNum'] = pd.to_numeric(test_x['CabinNum'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Display the updated train_x dataframe\n",
    "train_x[['Cabin', 'CabinDeck', 'CabinNum', 'CabinSide']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data divided in deck/num/side, let's now see the distribution and the nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for CabinDeck:\n",
      "CabinDeck\n",
      "F      2504\n",
      "G      2296\n",
      "E       799\n",
      "B       707\n",
      "C       672\n",
      "D       433\n",
      "A       232\n",
      "NaN     175\n",
      "T         5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in CabinDeck: 175 (2.24%)\n",
      "\n",
      "Distribution for CabinNum:\n",
      "CabinNum\n",
      "<NA>    175\n",
      "82       28\n",
      "19       21\n",
      "56       20\n",
      "86       20\n",
      "       ... \n",
      "1607      1\n",
      "1133      1\n",
      "1669      1\n",
      "1866      1\n",
      "1519      1\n",
      "Name: count, Length: 1781, dtype: Int64\n",
      "\n",
      "Missing values in CabinNum: 175 (2.24%)\n",
      "\n",
      "Distribution for CabinSide:\n",
      "CabinSide\n",
      "S      3881\n",
      "P      3767\n",
      "NaN     175\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in CabinSide: 175 (2.24%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution and missing values for CabinDeck, CabinNum, and CabinSide\n",
    "for column in ['CabinDeck', 'CabinNum', 'CabinSide']:\n",
    "    print(f\"Distribution for {column}:\")\n",
    "    print(train_x[column].value_counts(dropna=False))\n",
    "    print(f\"\\nMissing values in {column}: {train_x[column].isnull().sum()} ({train_x[column].isnull().mean() * 100:.2f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for CabinSide = S:\n",
      "\n",
      "CabinDeck distribution:\n",
      "CabinDeck\n",
      "F    1211\n",
      "G    1164\n",
      "E     404\n",
      "B     393\n",
      "C     370\n",
      "D     212\n",
      "A     126\n",
      "T       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution for CabinSide = P:\n",
      "\n",
      "CabinDeck distribution:\n",
      "CabinDeck\n",
      "F    1293\n",
      "G    1132\n",
      "E     395\n",
      "B     314\n",
      "C     302\n",
      "D     221\n",
      "A     106\n",
      "T       4\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution of CabinDeck based on CabinSide\n",
    "for side in ['S', 'P']:\n",
    "    print(f\"Distribution for CabinSide = {side}:\\n\")\n",
    "    \n",
    "    # CabinDeck distribution\n",
    "    cabin_deck_distribution = train_x[train_x['CabinSide'] == side]['CabinDeck'].value_counts(dropna=False)\n",
    "    print(f\"CabinDeck distribution:\\n{cabin_deck_distribution}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for CryoSleep = True:\n",
      "\n",
      "           Count  Percentage  Percentage of Total CabinDeck\n",
      "CabinDeck                                                  \n",
      "G           1252       44.44                          54.53\n",
      "F            503       17.86                          20.09\n",
      "B            390       13.84                          55.16\n",
      "C            276        9.80                          41.07\n",
      "E            163        5.79                          20.40\n",
      "D             97        3.44                          22.40\n",
      "NaN           74        2.63                          42.29\n",
      "A             62        2.20                          26.72\n",
      "Distribution for CryoSleep = False:\n",
      "\n",
      "           Count  Percentage  Percentage of Total CabinDeck\n",
      "CabinDeck                                                  \n",
      "F           2001       39.97                          79.91\n",
      "G           1044       20.85                          45.47\n",
      "E            636       12.70                          79.60\n",
      "C            396        7.91                          58.93\n",
      "D            336        6.71                          77.60\n",
      "B            317        6.33                          44.84\n",
      "A            170        3.40                          73.28\n",
      "NaN          101        2.02                          57.71\n",
      "T              5        0.10                         100.00\n"
     ]
    }
   ],
   "source": [
    "# Distribution of CabinNum based on CryoSleep\n",
    "for side in [True, False]:\n",
    "    print(f\"Distribution for CryoSleep = {side}:\\n\")\n",
    "    \n",
    "    # CabinDeck distribution\n",
    "    cabin_deck_distribution = train_x[train_x['CryoSleep'] == side]['CabinDeck'].value_counts(dropna=False)\n",
    "    cabin_deck_percentages = (cabin_deck_distribution / cabin_deck_distribution.sum() * 100).round(2)\n",
    "    \n",
    "    # Combine counts and percentages into a DataFrame\n",
    "    cabin_deck_distribution_df = pd.DataFrame({\n",
    "        'Count': cabin_deck_distribution,\n",
    "        'Percentage': cabin_deck_percentages\n",
    "    })\n",
    "    \n",
    "    # Calculate percentage relative to total passengers in each CabinDeck\n",
    "    total_cabin_deck_counts = train_x['CabinDeck'].value_counts(dropna=False)\n",
    "    cabin_deck_distribution_df['Percentage of Total CabinDeck'] = (\n",
    "        cabin_deck_distribution / total_cabin_deck_counts * 100\n",
    "    ).round(2)\n",
    "    \n",
    "    print(cabin_deck_distribution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the results we can observe that the same decks exists on both sides, so we are not obtaining any information from that. As I see it, the CabinDeck and CabinNum don't give us any useful information and are categorical variants with lots of different values, so in order to not increase exponentially the complexity of the problem, I will remove them. On the other side, the CabinSide consist in only two different values that we can encode into a single boolean variant. The main problem is what are we going to do with the missing values because I don't have any information about when a passenger is in the Port or the Starboard, I will use an existing Missing Data Imputation method, that I will select afterwards.\n",
    "\n",
    "Maybe use the CabinDeck info to impute missing CryoSleep values???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>isCabinPort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CabinSide  isCabinPort\n",
       "4132         P            1\n",
       "7217         P            1\n",
       "7216         P            1\n",
       "7968         S            0\n",
       "50           S            0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for HomePlanet\n",
    "train_x['isCabinPort'] = (train_x['CabinSide'] == 'P').astype(int)\n",
    "\n",
    "val_x['isCabinPort'] = (val_x['CabinSide'] == 'P').astype(int)\n",
    "\n",
    "test_x['isCabinPort'] = (test_x['CabinSide'] == 'P').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['CabinSide', 'isCabinPort']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination \n",
    "The planet the passenger will be debarking to.\n",
    "\n",
    "Similar to the HomePlanet, this is a categorical value, so let's again see the class distribution and the number of unique values that exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination unique values:  ['TRAPPIST-1e' 'PSO J318.5-22' '55 Cancri e' nan]\n",
      "Missing values in Destination:  166 (2.12%)\n"
     ]
    }
   ],
   "source": [
    "# First I check how many different values we have in this variant (Destination)\n",
    "print(\"Destination unique values: \", train_x['Destination'].unique())\n",
    "\n",
    "# And also if there are any missing values and how many\n",
    "print(\"Missing values in Destination: \", train_x['Destination'].isnull().sum(), f\"({train_x['Destination'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's solve the issue with the missing values, we can assume that members of the same group have the same destination, so the first approach will be to assign the existing value of one member of the group to other members that have a null value in the Destination variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some groups have inconsistent Destinations:\n",
      "Group\n",
      "0008    2\n",
      "0020    3\n",
      "0044    2\n",
      "0067    3\n",
      "0099    2\n",
      "       ..\n",
      "9219    2\n",
      "9220    2\n",
      "9227    2\n",
      "9231    2\n",
      "9280    2\n",
      "Name: Destination, Length: 612, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if all members of the same group have the same Destination\n",
    "group_destination_check = train_x.groupby('Group')['Destination'].nunique()\n",
    "\n",
    "# Find groups with more than one unique Destination\n",
    "inconsistent_groups = group_destination_check[group_destination_check > 1]\n",
    "\n",
    "# Print the result\n",
    "if inconsistent_groups.empty:\n",
    "    print(\"All members of the same group have the same Destination.\")\n",
    "else:\n",
    "    print(\"Some groups have inconsistent Destinations:\")\n",
    "    print(inconsistent_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can't follow this approach now, let's see the class distribution in more detail to see the frequency of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination distribution (counts):\n",
      "Destination\n",
      "TRAPPIST-1e      5326\n",
      "55 Cancri e      1616\n",
      "PSO J318.5-22     715\n",
      "NaN               166\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Destination distribution (percentages):\n",
      "Destination\n",
      "TRAPPIST-1e      68.08\n",
      "55 Cancri e      20.66\n",
      "PSO J318.5-22     9.14\n",
      "NaN               2.12\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution for the Destination column\n",
    "destination_distribution = train_x['Destination'].value_counts(dropna=False)\n",
    "destination_percentages = (train_x['Destination'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"Destination distribution (counts):\")\n",
    "print(destination_distribution)\n",
    "print(\"\\nDestination distribution (percentages):\")\n",
    "print(destination_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the passengers go to TRAPPIST-1e, I could simply give that Destination to all the empty values, however I will better let a Missing Data Imputation method do that job, now let's just do the one-hot encoding to pass this variable to two boolean features that tell if destination isTrappist or isCancri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>isTrappist</th>\n",
       "      <th>isCancri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Destination  isTrappist  isCancri\n",
       "4132    TRAPPIST-1e           1         0\n",
       "7217    TRAPPIST-1e           1         0\n",
       "7216  PSO J318.5-22           0         0\n",
       "7968    55 Cancri e           0         1\n",
       "50      TRAPPIST-1e           1         0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for Destination\n",
    "train_x['isTrappist'] = (train_x['Destination'] == 'TRAPPIST-1e').astype(int)\n",
    "train_x['isCancri'] = (train_x['Destination'] == '55 Cancri e').astype(int)\n",
    "\n",
    "val_x['isTrappist'] = (val_x['Destination'] == 'TRAPPIST-1e').astype(int)\n",
    "val_x['isCancri'] = (val_x['Destination'] == '55 Cancri e').astype(int)\n",
    "\n",
    "test_x['isTrappist'] = (test_x['Destination'] == 'TRAPPIST-1e').astype(int)\n",
    "test_x['isCancri'] = (test_x['Destination'] == '55 Cancri e').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['Destination', 'isTrappist', 'isCancri']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age \n",
    "The age of the passenger.\n",
    "\n",
    "This is a numerical variable that doesn't need to apply any encoding, let's see it distribution in detail and if there is any empty value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age distribution:\n",
      "count    7661.000000\n",
      "mean       28.829526\n",
      "std        14.517979\n",
      "min         0.000000\n",
      "25%        19.000000\n",
      "50%        27.000000\n",
      "75%        38.000000\n",
      "max        79.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Missing values in Age:\n",
      "train_x: 162 (2.07%)\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of Age\n",
    "age_distribution = train_x['Age'].describe()\n",
    "print(\"Age distribution:\")\n",
    "print(age_distribution)\n",
    "\n",
    "# Check for missing values in Age\n",
    "missing_age_train = train_x['Age'].isnull().sum()\n",
    "\n",
    "print(\"\\nMissing values in Age:\")\n",
    "print(f\"train_x: {missing_age_train} ({missing_age_train / len(train_x) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the other features, we have a ~2% of empty values, again we are not able to manually impute any of these values, so I do nothing here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIP \n",
    "Whether the passenger has paid for special VIP service during the voyage. This is a boolean feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIP distribution (counts):\n",
      "VIP\n",
      "False    7455\n",
      "NaN       189\n",
      "True      179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "VIP distribution (percentages):\n",
      "VIP\n",
      "False    95.30\n",
      "NaN       2.42\n",
      "True      2.29\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in VIP:  189 (2.42%)\n"
     ]
    }
   ],
   "source": [
    "# Print the distribution of VIP\n",
    "VIP_distribution = train_x['VIP'].value_counts(dropna=False)\n",
    "VIP_percentages = (train_x['VIP'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"VIP distribution (counts):\")\n",
    "print(VIP_distribution)\n",
    "print(\"\\nVIP distribution (percentages):\")\n",
    "print(VIP_percentages)\n",
    "\n",
    "print(\"Missing values in VIP: \", train_x['VIP'].isnull().sum(), f\"({train_x['VIP'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIP distribution when CryoSleep is True:\n",
      "VIP\n",
      "False    2725\n",
      "NaN        73\n",
      "True       19\n",
      "Name: count, dtype: int64\n",
      "VIP\n",
      "False    96.73\n",
      "NaN       2.59\n",
      "True      0.67\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter passengers where CryoSleep is True\n",
    "cryo_sleep_true = train_x[train_x['CryoSleep'] == 1]\n",
    "\n",
    "# Calculate the VIP distribution for passengers in CryoSleep\n",
    "vip_distribution_cryo_sleep = cryo_sleep_true['VIP'].value_counts(dropna=False)\n",
    "vip_percentages_cryo_sleep = (cryo_sleep_true['VIP'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "# Print the distribution\n",
    "print(\"VIP distribution when CryoSleep is True:\")\n",
    "print(vip_distribution_cryo_sleep)\n",
    "print(vip_percentages_cryo_sleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account that in a normal distribution only ~2.29% of the samples have VIP == True, that means that from our set of NaN values, we will only have 4 or 5 wrong values (Passenger with VIP == True where we set VIP == False), so I will set all empty VIP values to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in VIP after filling with False:\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\1786103325.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_x['VIP'] = train_x['VIP'].fillna(False)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\1786103325.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_x['VIP'] = val_x['VIP'].fillna(False)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_284\\1786103325.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_x['VIP'] = test_x['VIP'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the VIP column with False\n",
    "train_x['VIP'] = train_x['VIP'].fillna(False)\n",
    "val_x['VIP'] = val_x['VIP'].fillna(False)\n",
    "test_x['VIP'] = test_x['VIP'].fillna(False)\n",
    "\n",
    "# Verify if there are still missing values in VIP\n",
    "print(\"Missing values in VIP after filling with False:\")\n",
    "print(f\"train_x: {train_x['VIP'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['VIP'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['VIP'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoomService, FoodCourt, ShoppingMall, Spa, VRDeck \n",
    "Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. \n",
    "\n",
    "These are all numerical features, let's check their distribution and if there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for RoomService:\n",
      "count     7658.000000\n",
      "mean       226.560851\n",
      "std        673.028616\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         50.000000\n",
      "max      14327.000000\n",
      "Name: RoomService, dtype: float64\n",
      "\n",
      "Missing values in RoomService: 165 (2.11%)\n",
      "\n",
      "Distribution for FoodCourt:\n",
      "count     7654.000000\n",
      "mean       457.270577\n",
      "std       1585.986752\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         79.000000\n",
      "max      27723.000000\n",
      "Name: FoodCourt, dtype: float64\n",
      "\n",
      "Missing values in FoodCourt: 169 (2.16%)\n",
      "\n",
      "Distribution for ShoppingMall:\n",
      "count     7635.000000\n",
      "mean       176.503602\n",
      "std        620.864161\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         27.000000\n",
      "max      23492.000000\n",
      "Name: ShoppingMall, dtype: float64\n",
      "\n",
      "Missing values in ShoppingMall: 188 (2.40%)\n",
      "\n",
      "Distribution for Spa:\n",
      "count     7655.000000\n",
      "mean       313.306989\n",
      "std       1141.689289\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         62.000000\n",
      "max      22408.000000\n",
      "Name: Spa, dtype: float64\n",
      "\n",
      "Missing values in Spa: 168 (2.15%)\n",
      "\n",
      "Distribution for VRDeck:\n",
      "count     7654.000000\n",
      "mean       303.103083\n",
      "std       1146.761480\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         48.000000\n",
      "max      24133.000000\n",
      "Name: VRDeck, dtype: float64\n",
      "\n",
      "Missing values in VRDeck: 169 (2.16%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution and missing values for RoomService, FoodCourt, ShoppingMall, Spa, and VRDeck\n",
    "amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "for amenity in amenities:\n",
    "    print(f\"Distribution for {amenity}:\")\n",
    "    print(train_x[amenity].describe())\n",
    "    print(f\"\\nMissing values in {amenity}: {train_x[amenity].isnull().sum()} ({train_x[amenity].isnull().mean() * 100:.2f}%)\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
