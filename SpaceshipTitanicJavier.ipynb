{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic\n",
    "\n",
    "Our goal is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and Data Field Descriptions\n",
    "\n",
    "* **train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    * PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "    * HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    * CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    * Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    * Destination - The planet the passenger will be debarking to.\n",
    "    * Age - The age of the passenger.\n",
    "    * VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    * RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    * Name - The first and last names of the passenger.\n",
    "    * Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "* **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "* **sample_submission.csv** - A submission file in the correct format.\n",
    "    * PassengerId - Id for each passenger in the test set.\n",
    "    * Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T22:51:46.329307Z",
     "iopub.status.busy": "2025-04-17T22:51:46.328988Z",
     "iopub.status.idle": "2025-04-17T22:51:46.334775Z",
     "shell.execute_reply": "2025-04-17T22:51:46.333736Z",
     "shell.execute_reply.started": "2025-04-17T22:51:46.329278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset loading and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T22:53:41.701025Z",
     "iopub.status.busy": "2025-04-17T22:53:41.700621Z",
     "iopub.status.idle": "2025-04-17T22:53:41.799405Z",
     "shell.execute_reply": "2025-04-17T22:53:41.798601Z",
     "shell.execute_reply.started": "2025-04-17T22:53:41.701001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (8693, 14)\n",
      "Full test dataset shape is (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset into a Pandas Dataframe\n",
    "# Try to load the dataset from Kaggle, if not found, load from local directory\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "except FileNotFoundError:\n",
    "    train_df = pd.read_csv('kaggle/input/spaceship-titanic/train.csv')\n",
    "    test_df = pd.read_csv('kaggle/input/spaceship-titanic/test.csv')\n",
    "\n",
    "print(\"Full train dataset shape is {}\".format(train_df.shape))\n",
    "print(\"Full test dataset shape is {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# I split the datasets into features (X) and tag (Y)\n",
    "train_x = train_df.drop(columns=['Transported'])\n",
    "train_y = train_df['Transported'].astype(int)  # Convert boolean to int (0 or 1)\n",
    "\n",
    "test_x = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the different models used, I split the training set into train and validation, giving a 15% of the samples to the validation set. I set that percentage in order to have a dataset big enough to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape is (7389, 13)\n",
      "Validation dataset shape is (1304, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>4841_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>B/192/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>59.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mahamak Prefule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>1254_02</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/241/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Babix Breke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>4339_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/814/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>47.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Ranch Reste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>6493_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1050/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Terald Dillips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>5915_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>E/382/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>Garion Mcneiley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4549     4841_01     Europa      True   B/192/S    55 Cancri e  59.0  False   \n",
       "1182     1254_02       Mars     False   F/241/S    TRAPPIST-1e  27.0  False   \n",
       "4064     4339_01       Mars     False   F/814/S    TRAPPIST-1e  47.0  False   \n",
       "6156     6493_01      Earth      True  G/1050/P  PSO J318.5-22  18.0  False   \n",
       "5548     5915_01      Earth     False   E/382/S    TRAPPIST-1e  32.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall    Spa  VRDeck             Name  \n",
       "4549          0.0        0.0           0.0    0.0     0.0  Mahamak Prefule  \n",
       "1182          4.0        0.0         896.0  229.0     0.0      Babix Breke  \n",
       "4064       2044.0        0.0          95.0    0.0   120.0      Ranch Reste  \n",
       "6156          0.0        0.0           0.0    0.0     0.0   Terald Dillips  \n",
       "5548          0.0        0.0          39.0    0.0   749.0  Garion Mcneiley  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.15, random_state=0)\n",
    "\n",
    "print(\"Train dataset shape is {}\".format(train_x.shape))\n",
    "print(\"Validation dataset shape is {}\".format(val_x.shape))\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After separate a validation set from our training set, the next step is to preprocess the dataset, to do that I will check each individual feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId\n",
    "\n",
    "This variable represents a unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "At the begining it seems to be a variant without information to solve the problem, something like a name, however as it said, we can extract the number of members that each group has and that can be something relevant.\n",
    "However to know the number of members a group has, we have to use the whole dataset, trining + validation + test sets. To do this would be a problem in most cases because we are not sure that our dataset contain all the existent samples, however for this task, the description tells us that we have about two-thirds (~8700) of the passengers as the training set and THE REMAINING one-third (~4300) of the passengers as test, so we got at least partial information about all the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in PassengerId:\n",
      "train_x: 0\n",
      "test_x: 0\n",
      "val_x: 0\n",
      "Updated train_x:\n",
      "     PassengerId Group  numMembers\n",
      "4549     4841_01  4841           3\n",
      "1182     1254_02  1254           2\n",
      "4064     4339_01  4339           1\n",
      "6156     6493_01  6493           1\n",
      "5548     5915_01  5915           1\n",
      "\n",
      "Updated val_x:\n",
      "     PassengerId Group  numMembers\n",
      "3601     3868_05  3868           7\n",
      "6057     6405_02  6405           4\n",
      "2797     3021_01  3021           2\n",
      "7110     7578_01  7578           1\n",
      "8579     9158_01  9158           1\n",
      "\n",
      "Updated test_x:\n",
      "  PassengerId Group  numMembers\n",
      "0     0013_01  0013           1\n",
      "1     0018_01  0018           1\n",
      "2     0019_01  0019           1\n",
      "3     0021_01  0021           1\n",
      "4     0023_01  0023           1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in PassengerId\n",
    "print(\"Missing values in PassengerId:\")\n",
    "print(f\"train_x: {train_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['PassengerId'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['PassengerId'].isnull().sum()}\")\n",
    "\n",
    "# Extract group identifier (gggg) from PassengerId\n",
    "train_x['Group'] = train_x['PassengerId'].str.split('_').str[0]\n",
    "test_x['Group'] = test_x['PassengerId'].str.split('_').str[0]\n",
    "val_x['Group'] = val_x['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "# Combine all dataframes to calculate group sizes across all datasets\n",
    "combined_df = pd.concat([train_x, val_x, test_x])\n",
    "\n",
    "# Calculate the total number of members in each group\n",
    "group_sizes = combined_df['Group'].value_counts()\n",
    "\n",
    "# Add the numMembers column to each dataframe\n",
    "train_x['numMembers'] = train_x['Group'].map(group_sizes)\n",
    "val_x['numMembers'] = val_x['Group'].map(group_sizes)\n",
    "test_x['numMembers'] = test_x['Group'].map(group_sizes)\n",
    "\n",
    "# Display the updated dataframes\n",
    "print(\"Updated train_x:\")\n",
    "print(train_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated val_x:\")\n",
    "print(val_x[['PassengerId', 'Group', 'numMembers']].head())\n",
    "\n",
    "print(\"\\nUpdated test_x:\")\n",
    "print(test_x[['PassengerId', 'Group', 'numMembers']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can remove the columns PassengerId and Group, that don't give us any more information, however I will wait and remove all the useless columns after analyze all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomePlanet \n",
    "The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "This is a categorical feature, so we will need to encode it in some way in order to give the information to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet unique values:  ['Europa' 'Mars' 'Earth' nan]\n",
      "Missing values in HomePlanet:  167 (2.26%)\n"
     ]
    }
   ],
   "source": [
    "# First I check how many different values we have in this variant (HomePlanet)\n",
    "print(\"HomePlanet unique values: \", train_x['HomePlanet'].unique())\n",
    "\n",
    "# And also if there are any missing values and how many\n",
    "print(\"Missing values in HomePlanet: \", train_x['HomePlanet'].isnull().sum(), f\"({train_x['HomePlanet'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's solve the issue with the missing values, we can assume that members of the same group depart from the same planet, so the first approach will be to assign the existing value of one member of the group to other members that have a null value in the HomePlanet variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All members of the same group have the same HomePlanet.\n"
     ]
    }
   ],
   "source": [
    "# Check if all members of the same group have the same HomePlanet\n",
    "group_destination_check = train_x.groupby('Group')['HomePlanet'].nunique()\n",
    "\n",
    "# Find groups with more than one unique HomePlanet\n",
    "inconsistent_groups = group_destination_check[group_destination_check > 1]\n",
    "\n",
    "# Print the result\n",
    "if inconsistent_groups.empty:\n",
    "    print(\"All members of the same group have the same HomePlanet.\")\n",
    "else:\n",
    "    print(\"Some groups have inconsistent HomePlanet:\")\n",
    "    print(inconsistent_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\165029983.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\165029983.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_x['HomePlanet'] = test_x.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling:\n",
      "train_x: 92\n",
      "val_x: 19\n",
      "test_x: 46\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([train_x, val_x])\n",
    "\n",
    "# Fill missing HomePlanet values based on the group\n",
    "combined_df['HomePlanet'] = combined_df.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n",
    "test_x['HomePlanet'] = test_x.groupby('Group')['HomePlanet'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Update train_x, val_x, and test_x with the filled values from combined_df based on PassengerId\n",
    "train_x['HomePlanet'] = train_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "val_x['HomePlanet'] = val_x['PassengerId'].map(combined_df.set_index('PassengerId')['HomePlanet'])\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling:\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0064_02</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>E/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Colatz Keen</td>\n",
       "      <td>0064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "59     0064_02       Mars      True  E/3/S  TRAPPIST-1e  33.0  False   \n",
       "\n",
       "    RoomService  FoodCourt  ShoppingMall  Spa  VRDeck         Name Group  \\\n",
       "59          0.0        0.0           NaN  0.0     0.0  Colatz Keen  0064   \n",
       "\n",
       "    numMembers  \n",
       "59           2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check an example to see that everything is correct, in this case the group 0064 come from Mars\n",
    "combined_df[combined_df['Name'] == 'Colatz Keen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filled ~50% of the empty values based on the training set, however we still have a little bit more than a 1% of empty entries, so now I will check the class distribution, maybe there is one popular class and I can simply give that class value to the empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet distribution (counts):\n",
      "HomePlanet\n",
      "Earth     3904\n",
      "Europa    1848\n",
      "Mars      1545\n",
      "NaN         92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HomePlanet distribution (percentages):\n",
      "HomePlanet\n",
      "Earth     52.84\n",
      "Europa    25.01\n",
      "Mars      20.91\n",
      "NaN        1.25\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution for the HomePlanet column\n",
    "homeplanet_distribution = train_x['HomePlanet'].value_counts(dropna=False)\n",
    "homeplanet_percentages = (train_x['HomePlanet'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"HomePlanet distribution (counts):\")\n",
    "print(homeplanet_distribution)\n",
    "print(\"\\nHomePlanet distribution (percentages):\")\n",
    "print(homeplanet_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the distribution, if I assign Earth to the empty values, I will aim ~53% of the cases, taking into account that we have 1.25% of empty values, I will have ~0.6% of incorrect values with this approach, this is a very low percentage, so I go with this plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HomePlanet after filling with 'Earth':\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the HomePlanet column with 'Earth'\n",
    "train_x['HomePlanet'] = train_x['HomePlanet'].fillna('Earth')\n",
    "val_x['HomePlanet'] = val_x['HomePlanet'].fillna('Earth')\n",
    "test_x['HomePlanet'] = test_x['HomePlanet'].fillna('Earth')\n",
    "\n",
    "# Verify if there are still missing values in HomePlanet\n",
    "print(\"Missing values in HomePlanet after filling with 'Earth':\")\n",
    "print(f\"train_x: {train_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['HomePlanet'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['HomePlanet'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to train the model with this feature, we need to encode it, to do that I will use one-hot encoding that will add 1 more variable to the problem.\n",
    "\n",
    "The idea is to pass from HomePlanet to two boolean variables, isHomeEarth and isHomeEuropa, if both variants are False we still have the info that the HomePlanet is Mars without having to explicitly saving into another variant. With this approach I am assuming that the only possible HomePlanets are Earth, Mars and Europa, which is not crazy to say seeing the class distribution in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  isHomeEarth  isHomeEuropa\n",
       "4549     Europa            0             1\n",
       "1182       Mars            0             0\n",
       "4064       Mars            0             0\n",
       "6156      Earth            1             0\n",
       "5548      Earth            1             0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for HomePlanet\n",
    "train_x['isHomeEarth'] = (train_x['HomePlanet'] == 'Earth').astype(int)\n",
    "train_x['isHomeEuropa'] = (train_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "val_x['isHomeEarth'] = (val_x['HomePlanet'] == 'Earth').astype(int)\n",
    "val_x['isHomeEuropa'] = (val_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "test_x['isHomeEarth'] = (test_x['HomePlanet'] == 'Earth').astype(int)\n",
    "test_x['isHomeEuropa'] = (test_x['HomePlanet'] == 'Europa').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['HomePlanet', 'isHomeEarth', 'isHomeEuropa']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CryoSleep \n",
    "Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "This is a boolean variable, so we only have to cast it into integer, however first I need to check if there are any empty value and the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep distribution (counts):\n",
      "CryoSleep\n",
      "False    4619\n",
      "True     2585\n",
      "NaN       185\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CryoSleep distribution (percentages):\n",
      "CryoSleep\n",
      "False    62.51\n",
      "True     34.98\n",
      "NaN       2.50\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in CryoSleep:  185 (2.50%)\n"
     ]
    }
   ],
   "source": [
    "# Print the distribution of CryoSleep\n",
    "cryosleep_distribution = train_x['CryoSleep'].value_counts(dropna=False)\n",
    "cryosleep_percentages = (train_x['CryoSleep'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"CryoSleep distribution (counts):\")\n",
    "print(cryosleep_distribution)\n",
    "print(\"\\nCryoSleep distribution (percentages):\")\n",
    "print(cryosleep_percentages)\n",
    "\n",
    "print(\"Missing values in CryoSleep: \", train_x['CryoSleep'].isnull().sum(), f\"({train_x['CryoSleep'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar than with the HomePlanet, we have ~2.5% of empty values.\n",
    "\n",
    "In this case, we have the statement where if a passenger is in cryosleep, he is confined inside his cabin, so he won't spend any money on services, that means that variables RoomService, FoodCourt, ShoppingMall, Spa and VRDeck will be all 0.\n",
    "\n",
    "To confirm this, lets check:\n",
    "* When CryoSleep == True, sum(RoomService, FoodCourt, ShoppingMall, Spa and VRDeck) == 0.0\n",
    "* When CryoSleep == False, sum(RoomService, FoodCourt, ShoppingMall, Spa and VRDeck) > 0.0\n",
    "\n",
    "To do this check I will exclude samples with any of this fields empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep == True and all services == 0.0:\n",
      "True\n",
      "Number of samples: 2282\n",
      "\n",
      "CryoSleep == False and sum of services > 0.0:\n",
      "False\n",
      "Number of samples: 4161\n",
      "\n",
      "Rows where CryoSleep == False and sum of services == 0.0:\n",
      "     PassengerId HomePlanet CryoSleep     Cabin  Destination   Age    VIP  \\\n",
      "3626     3903_01      Earth     False   G/636/P  55 Cancri e   2.0  False   \n",
      "4015     4280_01       Mars     False   E/267/P  TRAPPIST-1e  24.0  False   \n",
      "2002     2137_03       Mars     False   F/423/P  55 Cancri e   4.0  False   \n",
      "3733     4001_07      Earth     False   G/659/S  TRAPPIST-1e   3.0    NaN   \n",
      "7529     8052_01      Earth     False  G/1302/S  TRAPPIST-1e   9.0  False   \n",
      "...          ...        ...       ...       ...          ...   ...    ...   \n",
      "4305     4592_01       Mars     False   F/862/S  TRAPPIST-1e   9.0  False   \n",
      "7316     7830_04      Earth     False  G/1268/S  TRAPPIST-1e   0.0  False   \n",
      "3455     3715_03      Earth     False   G/602/P  TRAPPIST-1e   2.0  False   \n",
      "2418     2595_01       Mars     False   F/533/P  55 Cancri e   0.0  False   \n",
      "3264     3499_04      Earth     False   G/574/P  TRAPPIST-1e   0.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall  Spa  VRDeck                Name  \\\n",
      "3626          0.0        0.0           0.0  0.0     0.0      Glendy Doughan   \n",
      "4015          0.0        0.0           0.0  0.0     0.0        Lidenx Icake   \n",
      "2002          0.0        0.0           0.0  0.0     0.0          Slig Queke   \n",
      "3733          0.0        0.0           0.0  0.0     0.0   Everly Lowelliott   \n",
      "7529          0.0        0.0           0.0  0.0     0.0         Duana Serry   \n",
      "...           ...        ...           ...  ...     ...                 ...   \n",
      "4305          0.0        0.0           0.0  0.0     0.0        Crunch Carté   \n",
      "7316          0.0        0.0           0.0  0.0     0.0       Eddiey Belley   \n",
      "3455          0.0        0.0           0.0  0.0     0.0      Vane Hubbarton   \n",
      "2418          0.0        0.0           0.0  0.0     0.0          Lies Cakie   \n",
      "3264          0.0        0.0           0.0  0.0     0.0  Allene Mccarveymon   \n",
      "\n",
      "     Group  numMembers  isHomeEarth  isHomeEuropa  \n",
      "3626  3903           6            1             0  \n",
      "4015  4280           1            0             0  \n",
      "2002  2137           3            0             0  \n",
      "3733  4001           7            1             0  \n",
      "7529  8052           2            1             0  \n",
      "...    ...         ...          ...           ...  \n",
      "4305  4592           4            0             0  \n",
      "7316  7830           4            1             0  \n",
      "3455  3715           4            1             0  \n",
      "2418  2595           4            0             0  \n",
      "3264  3499           4            1             0  \n",
      "\n",
      "[398 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exclude samples with any of the relevant fields empty\n",
    "filtered_df = train_x.dropna(subset=['CryoSleep', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'])\n",
    "\n",
    "# Check the conditions\n",
    "cryosleep_true = filtered_df[filtered_df['CryoSleep'] == True]\n",
    "cryosleep_false = filtered_df[filtered_df['CryoSleep'] == False]\n",
    "\n",
    "cryosleep_true_condition = cryosleep_true[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1).eq(0.0)\n",
    "cryosleep_false_condition = cryosleep_false[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1).gt(0.0)\n",
    "\n",
    "# Print the results\n",
    "print(\"CryoSleep == True and all services == 0.0:\")\n",
    "print(cryosleep_true_condition.all())\n",
    "print(f\"Number of samples: {len(cryosleep_true)}\")\n",
    "if not cryosleep_true_condition.all():\n",
    "    print(\"\\nRows where CryoSleep == True and all services != 0.0:\")\n",
    "    print(cryosleep_true[~cryosleep_true_condition])\n",
    "\n",
    "print(\"\\nCryoSleep == False and sum of services > 0.0:\")\n",
    "print(cryosleep_false_condition.all())\n",
    "print(f\"Number of samples: {len(cryosleep_false)}\")\n",
    "if not cryosleep_false_condition.all():\n",
    "    print(\"\\nRows where CryoSleep == False and sum of services == 0.0:\")\n",
    "    print(cryosleep_false[~cryosleep_false_condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, with the obtained results we can assume that if a passenger has spent something, he is not on cryosleep, however we CANNOT assume that if a passenger didn't spend anything, he is on cryosleep.\n",
    "\n",
    "So let's do a recap, taking into account the distribution (~62.5% False -- ~35% True), the most probable is that inside that ~2.5% of empty values this distribution also apply, so let's apply the rule where if a passenger has spent something, he is not on cryosleep and see the new distribution to evaluate the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep distribution (counts):\n",
      "CryoSleep\n",
      "False    4721\n",
      "True     2585\n",
      "NaN        83\n",
      "Name: count, dtype: int64\n",
      "\\CryoSleep distribution (percentages):\n",
      "CryoSleep\n",
      "False    63.89\n",
      "True     34.98\n",
      "NaN       1.12\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in CryoSleep:  83 (1.12%)\n"
     ]
    }
   ],
   "source": [
    "# When 'CryoSleep' is nan, if a passenger has spent something on 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa' or 'VRDeck', he is not on cryosleep, so we can fill 'CryoSleep' as False\n",
    "train_x.loc[train_x['CryoSleep'].isnull() & (train_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "val_x.loc[val_x['CryoSleep'].isnull() & (val_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "test_x.loc[train_x['CryoSleep'].isnull() & (test_x[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) > 0.0), 'CryoSleep'] = False\n",
    "\n",
    "# Print the updated distribution of CryoSleep\n",
    "cryosleep_distribution = train_x['CryoSleep'].value_counts(dropna=False)\n",
    "cryosleep_percentages = (train_x['CryoSleep'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"CryoSleep distribution (counts):\")\n",
    "print(cryosleep_distribution)\n",
    "print(\"\\CryoSleep distribution (percentages):\")\n",
    "print(cryosleep_percentages)\n",
    "\n",
    "print(\"Missing values in CryoSleep: \", train_x['CryoSleep'].isnull().sum(), f\"({train_x['CryoSleep'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 185 NaN values and now we have only 83, meaning that from that set of 185 samples, the ~55% of the samples are not CryoSleep and the remain percentage is still unknown, taking into account that approx. the ~62% of the samples inside a set are not CryoSleep, there is still a ~7% of the samples that can not be CryoSleep, this means that there are ~13 samples that are not CryoSleep, but didn't spend a penny. In total percentages this means that from the 7389 samples that the training set has, a ~0.18% of them will have this field wrong. So we can take the risk of assign CryoSleep == True to the rest of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in CryoSleep after filling with True:\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\1584031860.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_x['CryoSleep'] = train_x['CryoSleep'].fillna(True)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\1584031860.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_x['CryoSleep'] = val_x['CryoSleep'].fillna(True)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\1584031860.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_x['CryoSleep'] = test_x['CryoSleep'].fillna(True)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the CryoSleep column with True\n",
    "train_x['CryoSleep'] = train_x['CryoSleep'].fillna(True)\n",
    "val_x['CryoSleep'] = val_x['CryoSleep'].fillna(True)\n",
    "test_x['CryoSleep'] = test_x['CryoSleep'].fillna(True)\n",
    "\n",
    "# Verify if there are still missing values in CryoSleep\n",
    "print(\"Missing values in CryoSleep after filling with True:\")\n",
    "print(f\"train_x: {train_x['CryoSleep'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['CryoSleep'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['CryoSleep'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cast the boolean values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>numMembers</th>\n",
       "      <th>isHomeEarth</th>\n",
       "      <th>isHomeEuropa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>4841_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>1</td>\n",
       "      <td>B/192/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>59.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mahamak Prefule</td>\n",
       "      <td>4841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>1254_02</td>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>F/241/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Babix Breke</td>\n",
       "      <td>1254</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>4339_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>F/814/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>47.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Ranch Reste</td>\n",
       "      <td>4339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>6493_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>G/1050/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Terald Dillips</td>\n",
       "      <td>6493</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>5915_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>E/382/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>Garion Mcneiley</td>\n",
       "      <td>5915</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "4549     4841_01     Europa          1   B/192/S    55 Cancri e  59.0  False   \n",
       "1182     1254_02       Mars          0   F/241/S    TRAPPIST-1e  27.0  False   \n",
       "4064     4339_01       Mars          0   F/814/S    TRAPPIST-1e  47.0  False   \n",
       "6156     6493_01      Earth          1  G/1050/P  PSO J318.5-22  18.0  False   \n",
       "5548     5915_01      Earth          0   E/382/S    TRAPPIST-1e  32.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall    Spa  VRDeck             Name  \\\n",
       "4549          0.0        0.0           0.0    0.0     0.0  Mahamak Prefule   \n",
       "1182          4.0        0.0         896.0  229.0     0.0      Babix Breke   \n",
       "4064       2044.0        0.0          95.0    0.0   120.0      Ranch Reste   \n",
       "6156          0.0        0.0           0.0    0.0     0.0   Terald Dillips   \n",
       "5548          0.0        0.0          39.0    0.0   749.0  Garion Mcneiley   \n",
       "\n",
       "     Group  numMembers  isHomeEarth  isHomeEuropa  \n",
       "4549  4841           3            0             1  \n",
       "1182  1254           2            0             0  \n",
       "4064  4339           1            0             0  \n",
       "6156  6493           1            1             0  \n",
       "5548  5915           1            1             0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['CryoSleep'] = train_x['CryoSleep'].astype(int)\n",
    "val_x['CryoSleep'] = val_x['CryoSleep'].astype(int)\n",
    "test_x['CryoSleep'] = test_x['CryoSleep'].astype(int)\n",
    "\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin\n",
    "The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard. So first let's separate each value and save them in different columns, but even before that, let's see if multiple passengers can stare in the same cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in Cabin: 5719\n",
      "Number of total values in Cabin: 7389\n",
      "Most common Cabin value: B/11/S\n",
      "Count of most common Cabin value: 7\n"
     ]
    }
   ],
   "source": [
    "# Number of unique values in Cabin\n",
    "print(\"Number of unique values in Cabin:\", train_x['Cabin'].nunique()) # Not counting NaN values\n",
    "print(\"Number of total values in Cabin:\", len(train_x['Cabin']))\n",
    "\n",
    "# Print the Cabin value with the most occurrences and its count\n",
    "most_common_cabin = train_x['Cabin'].mode()[0]\n",
    "print(\"Most common Cabin value:\", most_common_cabin)\n",
    "print(\"Count of most common Cabin value:\", train_x['Cabin'].value_counts().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that several passenger can be found in the same cabin. Let's now see the number of missing values, because maybe we can restore them based on the Group of the passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Cabin: 158 (2.14%)\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in Cabin\n",
    "print(\"Missing values in Cabin:\", train_x['Cabin'].isnull().sum(), f\"({train_x['Cabin'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some groups have inconsistent Cabin:\n",
      "Group\n",
      "0006    2\n",
      "0064    2\n",
      "0067    2\n",
      "0091    2\n",
      "0099    2\n",
      "       ..\n",
      "9128    2\n",
      "9208    2\n",
      "9219    2\n",
      "9220    2\n",
      "9231    2\n",
      "Name: Cabin, Length: 331, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if all members of the same Group have the same Cabin\n",
    "group_destination_check = train_x.groupby('Group')['Cabin'].nunique()\n",
    "\n",
    "# Find groups with more than one unique Cabin\n",
    "inconsistent_groups = group_destination_check[group_destination_check > 1]\n",
    "\n",
    "# Print the result\n",
    "if inconsistent_groups.empty:\n",
    "    print(\"All members of the same group have the same Cabin.\")\n",
    "else:\n",
    "    print(\"Some groups have inconsistent Cabin:\")\n",
    "    print(inconsistent_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's not secured that members of the same group travel in the same cabin. So let's now split the Cabin string into their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>B/192/S</td>\n",
       "      <td>B</td>\n",
       "      <td>192</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>F/241/S</td>\n",
       "      <td>F</td>\n",
       "      <td>241</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>F/814/S</td>\n",
       "      <td>F</td>\n",
       "      <td>814</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>G/1050/P</td>\n",
       "      <td>G</td>\n",
       "      <td>1050</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>E/382/S</td>\n",
       "      <td>E</td>\n",
       "      <td>382</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cabin CabinDeck  CabinNum CabinSide\n",
       "4549   B/192/S         B       192         S\n",
       "1182   F/241/S         F       241         S\n",
       "4064   F/814/S         F       814         S\n",
       "6156  G/1050/P         G      1050         P\n",
       "5548   E/382/S         E       382         S"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the Cabin column into deck, num, and side\n",
    "train_x[['CabinDeck', 'CabinNum', 'CabinSide']] = train_x['Cabin'].str.split('/', expand=True)\n",
    "val_x[['CabinDeck', 'CabinNum', 'CabinSide']] = val_x['Cabin'].str.split('/', expand=True)\n",
    "test_x[['CabinDeck', 'CabinNum', 'CabinSide']] = test_x['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Convert CabinNum to numeric for potential numerical analysis\n",
    "train_x['CabinNum'] = pd.to_numeric(train_x['CabinNum'], errors='coerce').astype('Int64')\n",
    "val_x['CabinNum'] = pd.to_numeric(val_x['CabinNum'], errors='coerce').astype('Int64')\n",
    "test_x['CabinNum'] = pd.to_numeric(test_x['CabinNum'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Display the updated train_x dataframe\n",
    "train_x[['Cabin', 'CabinDeck', 'CabinNum', 'CabinSide']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data divided in deck/num/side, let's now see the distribution and the nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for CabinDeck:\n",
      "CabinDeck\n",
      "F      2374\n",
      "G      2154\n",
      "E       768\n",
      "B       669\n",
      "C       629\n",
      "D       409\n",
      "A       223\n",
      "NaN     158\n",
      "T         5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in CabinDeck: 158 (2.14%)\n",
      "\n",
      "Distribution for CabinNum:\n",
      "CabinNum\n",
      "<NA>    158\n",
      "82       25\n",
      "19       20\n",
      "230      19\n",
      "65       19\n",
      "       ... \n",
      "1870      1\n",
      "1532      1\n",
      "1812      1\n",
      "1761      1\n",
      "744       1\n",
      "Name: count, Length: 1764, dtype: Int64\n",
      "\n",
      "Missing values in CabinNum: 158 (2.14%)\n",
      "\n",
      "Distribution for CabinSide:\n",
      "CabinSide\n",
      "S      3653\n",
      "P      3578\n",
      "NaN     158\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in CabinSide: 158 (2.14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution and missing values for CabinDeck, CabinNum, and CabinSide\n",
    "for column in ['CabinDeck', 'CabinNum', 'CabinSide']:\n",
    "    print(f\"Distribution for {column}:\")\n",
    "    print(train_x[column].value_counts(dropna=False))\n",
    "    print(f\"\\nMissing values in {column}: {train_x[column].isnull().sum()} ({train_x[column].isnull().mean() * 100:.2f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for CabinSide = S:\n",
      "\n",
      "CabinDeck distribution:\n",
      "CabinDeck\n",
      "F    1143\n",
      "G    1093\n",
      "E     379\n",
      "B     372\n",
      "C     344\n",
      "D     200\n",
      "A     121\n",
      "T       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution for CabinSide = P:\n",
      "\n",
      "CabinDeck distribution:\n",
      "CabinDeck\n",
      "F    1231\n",
      "G    1061\n",
      "E     389\n",
      "B     297\n",
      "C     285\n",
      "D     209\n",
      "A     102\n",
      "T       4\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution of CabinDeck based on CabinSide\n",
    "for side in ['S', 'P']:\n",
    "    print(f\"Distribution for CabinSide = {side}:\\n\")\n",
    "    \n",
    "    # CabinDeck distribution\n",
    "    cabin_deck_distribution = train_x[train_x['CabinSide'] == side]['CabinDeck'].value_counts(dropna=False)\n",
    "    print(f\"CabinDeck distribution:\\n{cabin_deck_distribution}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for CryoSleep = True:\n",
      "\n",
      "           Count  Percentage  Percentage of Total CabinDeck\n",
      "CabinDeck                                                  \n",
      "G           1185       44.42                          55.01\n",
      "F            478       17.92                          20.13\n",
      "B            371       13.91                          55.46\n",
      "C            261        9.78                          41.49\n",
      "E            157        5.88                          20.44\n",
      "D             87        3.26                          21.27\n",
      "NaN           67        2.51                          42.41\n",
      "A             62        2.32                          27.80\n",
      "Distribution for CryoSleep = False:\n",
      "\n",
      "           Count  Percentage  Percentage of Total CabinDeck\n",
      "CabinDeck                                                  \n",
      "F           1896       40.16                          79.87\n",
      "G            969       20.53                          44.99\n",
      "E            611       12.94                          79.56\n",
      "C            368        7.79                          58.51\n",
      "D            322        6.82                          78.73\n",
      "B            298        6.31                          44.54\n",
      "A            161        3.41                          72.20\n",
      "NaN           91        1.93                          57.59\n",
      "T              5        0.11                         100.00\n"
     ]
    }
   ],
   "source": [
    "# Distribution of CabinNum based on CryoSleep\n",
    "for side in [True, False]:\n",
    "    print(f\"Distribution for CryoSleep = {side}:\\n\")\n",
    "    \n",
    "    # CabinDeck distribution\n",
    "    cabin_deck_distribution = train_x[train_x['CryoSleep'] == side]['CabinDeck'].value_counts(dropna=False)\n",
    "    cabin_deck_percentages = (cabin_deck_distribution / cabin_deck_distribution.sum() * 100).round(2)\n",
    "    \n",
    "    # Combine counts and percentages into a DataFrame\n",
    "    cabin_deck_distribution_df = pd.DataFrame({\n",
    "        'Count': cabin_deck_distribution,\n",
    "        'Percentage': cabin_deck_percentages\n",
    "    })\n",
    "    \n",
    "    # Calculate percentage relative to total passengers in each CabinDeck\n",
    "    total_cabin_deck_counts = train_x['CabinDeck'].value_counts(dropna=False)\n",
    "    cabin_deck_distribution_df['Percentage of Total CabinDeck'] = (\n",
    "        cabin_deck_distribution / total_cabin_deck_counts * 100\n",
    "    ).round(2)\n",
    "    \n",
    "    print(cabin_deck_distribution_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability of being transported based on CabinSide:\n",
      "Transported         0         1\n",
      "CabinSide                      \n",
      "P            0.548351  0.451649\n",
      "S            0.443197  0.556803\n"
     ]
    }
   ],
   "source": [
    "# Check if the probability of being transported is biased on CabinSide\n",
    "aux_df = train_x.copy()\n",
    "aux_df['Transported'] = train_y\n",
    "\n",
    "cabin_side_distribution = aux_df.groupby('CabinSide')['Transported'].value_counts(normalize=True).unstack()\n",
    "\n",
    "print(\"\\nProbability of being transported based on CabinSide:\")\n",
    "print(cabin_side_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability of being transported based on CabinDeck:\n",
      "Transported         0         1\n",
      "CabinDeck                      \n",
      "A            0.502242  0.497758\n",
      "B            0.255605  0.744395\n",
      "C            0.325914  0.674086\n",
      "D            0.574572  0.425428\n",
      "E            0.636719  0.363281\n",
      "F            0.563184  0.436816\n",
      "G            0.477252  0.522748\n",
      "T            0.800000  0.200000\n"
     ]
    }
   ],
   "source": [
    "# Check if the probability of being transported is biased on CabinDeck\n",
    "aux_df = train_x.copy()\n",
    "aux_df['Transported'] = train_y\n",
    "\n",
    "cabin_side_distribution = aux_df.groupby('CabinDeck')['Transported'].value_counts(normalize=True).unstack()\n",
    "\n",
    "print(\"\\nProbability of being transported based on CabinDeck:\")\n",
    "print(cabin_side_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the results we can observe that the same decks exists on both sides, so we are not obtaining any information from that. As I see it, the CabinDeck and CabinNum don't give us any useful information and are categorical variants with lots of different values, so in order to not increase exponentially the complexity of the problem, I will remove them. On the other side, the CabinSide consist in only two different values that we can encode into a single boolean variant, however, it seems that it also doesn't give us any useful or discriminatory information, so we will remove all these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination \n",
    "The planet the passenger will be debarking to.\n",
    "\n",
    "Similar to the HomePlanet, this is a categorical value, so let's again see the class distribution and the number of unique values that exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination unique values:  ['55 Cancri e' 'TRAPPIST-1e' 'PSO J318.5-22' nan]\n",
      "Missing values in Destination:  158 (2.14%)\n"
     ]
    }
   ],
   "source": [
    "# First I check how many different values we have in this variant (Destination)\n",
    "print(\"Destination unique values: \", train_x['Destination'].unique())\n",
    "\n",
    "# And also if there are any missing values and how many\n",
    "print(\"Missing values in Destination: \", train_x['Destination'].isnull().sum(), f\"({train_x['Destination'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's solve the issue with the missing values, we can assume that members of the same group have the same destination, so the first approach will be to assign the existing value of one member of the group to other members that have a null value in the Destination variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some groups have inconsistent Destinations:\n",
      "Group\n",
      "0008    2\n",
      "0020    3\n",
      "0044    2\n",
      "0067    3\n",
      "0099    2\n",
      "       ..\n",
      "9205    2\n",
      "9219    2\n",
      "9220    2\n",
      "9227    2\n",
      "9280    2\n",
      "Name: Destination, Length: 559, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if all members of the same group have the same Destination\n",
    "group_destination_check = train_x.groupby('Group')['Destination'].nunique()\n",
    "\n",
    "# Find groups with more than one unique Destination\n",
    "inconsistent_groups = group_destination_check[group_destination_check > 1]\n",
    "\n",
    "# Print the result\n",
    "if inconsistent_groups.empty:\n",
    "    print(\"All members of the same group have the same Destination.\")\n",
    "else:\n",
    "    print(\"Some groups have inconsistent Destinations:\")\n",
    "    print(inconsistent_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can't follow this approach now, let's see the class distribution in more detail to see the frequency of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination distribution (counts):\n",
      "Destination\n",
      "TRAPPIST-1e      5039\n",
      "55 Cancri e      1524\n",
      "PSO J318.5-22     668\n",
      "NaN               158\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Destination distribution (percentages):\n",
      "Destination\n",
      "TRAPPIST-1e      68.20\n",
      "55 Cancri e      20.63\n",
      "PSO J318.5-22     9.04\n",
      "NaN               2.14\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution for the Destination column\n",
    "destination_distribution = train_x['Destination'].value_counts(dropna=False)\n",
    "destination_percentages = (train_x['Destination'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"Destination distribution (counts):\")\n",
    "print(destination_distribution)\n",
    "print(\"\\nDestination distribution (percentages):\")\n",
    "print(destination_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the passengers go to TRAPPIST-1e, I could simply give that Destination to all the empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in Destination with 'TRAPPIST-1e'\n",
    "train_x['Destination'] = train_x['Destination'].fillna('TRAPPIST-1e')\n",
    "val_x['Destination'] = val_x['Destination'].fillna('TRAPPIST-1e')\n",
    "test_x['Destination'] = test_x['Destination'].fillna('TRAPPIST-1e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's just do the one-hot encoding to pass this variable to two boolean features that tell if destination isTrappist or isCancri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>isTrappist</th>\n",
       "      <th>isCancri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Destination  isTrappist  isCancri\n",
       "4549    55 Cancri e           0         1\n",
       "1182    TRAPPIST-1e           1         0\n",
       "4064    TRAPPIST-1e           1         0\n",
       "6156  PSO J318.5-22           0         0\n",
       "5548    TRAPPIST-1e           1         0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding for Destination\n",
    "train_x['isTrappist'] = (train_x['Destination'] == 'TRAPPIST-1e').astype(int)\n",
    "train_x['isCancri'] = (train_x['Destination'] == '55 Cancri e').astype(int)\n",
    "\n",
    "val_x['isTrappist'] = (val_x['Destination'] == 'TRAPPIST-1e').astype(int)\n",
    "val_x['isCancri'] = (val_x['Destination'] == '55 Cancri e').astype(int)\n",
    "\n",
    "test_x['isTrappist'] = (test_x['Destination'] == 'TRAPPIST-1e').astype(int)\n",
    "test_x['isCancri'] = (test_x['Destination'] == '55 Cancri e').astype(int)\n",
    "\n",
    "# Verify the new columns\n",
    "train_x[['Destination', 'isTrappist', 'isCancri']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age \n",
    "The age of the passenger.\n",
    "\n",
    "This is a numerical variable that doesn't need to apply any encoding, let's see it distribution in detail and if there is any empty value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age distribution:\n",
      "count    7233.000000\n",
      "mean       28.822757\n",
      "std        14.471338\n",
      "min         0.000000\n",
      "25%        19.000000\n",
      "50%        27.000000\n",
      "75%        38.000000\n",
      "max        79.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Missing values in Age:\n",
      "train_x: 156 (2.11%)\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of Age\n",
    "age_distribution = train_x['Age'].describe()\n",
    "print(\"Age distribution:\")\n",
    "print(age_distribution)\n",
    "\n",
    "# Check for missing values in Age\n",
    "missing_age_train = train_x['Age'].isnull().sum()\n",
    "\n",
    "print(\"\\nMissing values in Age:\")\n",
    "print(f\"train_x: {missing_age_train} ({missing_age_train / len(train_x) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the other features, we have a ~2% of empty values, let's use the mean to fill the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the mean to fill the NaN values.\n",
    "train_x['Age'] = train_x['Age'].fillna(train_x['Age'].mean())\n",
    "val_x['Age'] = val_x['Age'].fillna(val_x['Age'].mean())\n",
    "test_x['Age'] = test_x['Age'].fillna(test_x['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIP \n",
    "Whether the passenger has paid for special VIP service during the voyage. This is a boolean feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIP distribution (counts):\n",
      "VIP\n",
      "False    7041\n",
      "NaN       181\n",
      "True      167\n",
      "Name: count, dtype: int64\n",
      "\n",
      "VIP distribution (percentages):\n",
      "VIP\n",
      "False    95.29\n",
      "NaN       2.45\n",
      "True      2.26\n",
      "Name: proportion, dtype: float64\n",
      "Missing values in VIP:  181 (2.45%)\n"
     ]
    }
   ],
   "source": [
    "# Print the distribution of VIP\n",
    "VIP_distribution = train_x['VIP'].value_counts(dropna=False)\n",
    "VIP_percentages = (train_x['VIP'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "print(\"VIP distribution (counts):\")\n",
    "print(VIP_distribution)\n",
    "print(\"\\nVIP distribution (percentages):\")\n",
    "print(VIP_percentages)\n",
    "\n",
    "print(\"Missing values in VIP: \", train_x['VIP'].isnull().sum(), f\"({train_x['VIP'].isnull().sum()/len(train_x)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIP distribution when CryoSleep is True:\n",
      "VIP\n",
      "False    2580\n",
      "NaN        71\n",
      "True       17\n",
      "Name: count, dtype: int64\n",
      "VIP\n",
      "False    96.70\n",
      "NaN       2.66\n",
      "True      0.64\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter passengers where CryoSleep is True\n",
    "cryo_sleep_true = train_x[train_x['CryoSleep'] == 1]\n",
    "\n",
    "# Calculate the VIP distribution for passengers in CryoSleep\n",
    "vip_distribution_cryo_sleep = cryo_sleep_true['VIP'].value_counts(dropna=False)\n",
    "vip_percentages_cryo_sleep = (cryo_sleep_true['VIP'].value_counts(normalize=True, dropna=False) * 100).round(2)\n",
    "\n",
    "# Print the distribution\n",
    "print(\"VIP distribution when CryoSleep is True:\")\n",
    "print(vip_distribution_cryo_sleep)\n",
    "print(vip_percentages_cryo_sleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account that in a normal distribution only ~2.29% of the samples have VIP == True, that means that from our set of NaN values, we will only have 4 or 5 wrong values (Passenger with VIP == True where we set VIP == False), so I will set all empty VIP values to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in VIP after filling with False:\n",
      "train_x: 0\n",
      "val_x: 0\n",
      "test_x: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\1786103325.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_x['VIP'] = train_x['VIP'].fillna(False)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\1786103325.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_x['VIP'] = val_x['VIP'].fillna(False)\n",
      "C:\\Users\\javie\\AppData\\Local\\Temp\\ipykernel_24364\\1786103325.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_x['VIP'] = test_x['VIP'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values in the VIP column with False\n",
    "train_x['VIP'] = train_x['VIP'].fillna(False)\n",
    "val_x['VIP'] = val_x['VIP'].fillna(False)\n",
    "test_x['VIP'] = test_x['VIP'].fillna(False)\n",
    "\n",
    "# Verify if there are still missing values in VIP\n",
    "print(\"Missing values in VIP after filling with False:\")\n",
    "print(f\"train_x: {train_x['VIP'].isnull().sum()}\")\n",
    "print(f\"val_x: {val_x['VIP'].isnull().sum()}\")\n",
    "print(f\"test_x: {test_x['VIP'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoomService, FoodCourt, ShoppingMall, Spa, VRDeck \n",
    "Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. \n",
    "\n",
    "These are all numerical features, let's check their distribution and if there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for RoomService:\n",
      "count     7231.000000\n",
      "mean       230.348776\n",
      "std        683.342179\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         51.500000\n",
      "max      14327.000000\n",
      "Name: RoomService, dtype: float64\n",
      "\n",
      "Missing values in RoomService: 158 (2.14%)\n",
      "\n",
      "Distribution for FoodCourt:\n",
      "count     7232.000000\n",
      "mean       453.941372\n",
      "std       1579.658236\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         77.000000\n",
      "max      27723.000000\n",
      "Name: FoodCourt, dtype: float64\n",
      "\n",
      "Missing values in FoodCourt: 157 (2.12%)\n",
      "\n",
      "Distribution for ShoppingMall:\n",
      "count     7207.000000\n",
      "mean       177.340364\n",
      "std        627.384360\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         28.000000\n",
      "max      23492.000000\n",
      "Name: ShoppingMall, dtype: float64\n",
      "\n",
      "Missing values in ShoppingMall: 182 (2.46%)\n",
      "\n",
      "Distribution for Spa:\n",
      "count     7229.000000\n",
      "mean       308.818232\n",
      "std       1113.812818\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         61.000000\n",
      "max      18572.000000\n",
      "Name: Spa, dtype: float64\n",
      "\n",
      "Missing values in Spa: 160 (2.17%)\n",
      "\n",
      "Distribution for VRDeck:\n",
      "count     7235.000000\n",
      "mean       304.099654\n",
      "std       1149.882901\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%         46.000000\n",
      "max      24133.000000\n",
      "Name: VRDeck, dtype: float64\n",
      "\n",
      "Missing values in VRDeck: 154 (2.08%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution and missing values for RoomService, FoodCourt, ShoppingMall, Spa, and VRDeck\n",
    "amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "for amenity in amenities:\n",
    "    print(f\"Distribution for {amenity}:\")\n",
    "    print(train_x[amenity].describe())\n",
    "    print(f\"\\nMissing values in {amenity}: {train_x[amenity].isnull().sum()} ({train_x[amenity].isnull().mean() * 100:.2f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from previous observations that when a passenger is on CryoSleep, he won't spend a penny on amenities, so let's fill with 0 these rows where CryoSleep is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill amenities with 0 where CryoSleep is True\n",
    "for col in amenities:\n",
    "    train_x.loc[train_x['CryoSleep'] == 1, col] = train_x.loc[train_x['CryoSleep'] == 1, col].fillna(0.0)\n",
    "    val_x.loc[val_x['CryoSleep'] == 1, col] = val_x.loc[val_x['CryoSleep'] == 1, col].fillna(0.0)\n",
    "    test_x.loc[test_x['CryoSleep'] == 1, col] = test_x.loc[test_x['CryoSleep'] == 1, col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in RoomService: 96 (1.30%)\n",
      "Missing values in FoodCourt: 96 (1.30%)\n",
      "Missing values in ShoppingMall: 98 (1.33%)\n",
      "Missing values in Spa: 105 (1.42%)\n",
      "Missing values in VRDeck: 93 (1.26%)\n"
     ]
    }
   ],
   "source": [
    "for amenity in amenities: print(f\"Missing values in {amenity}: {train_x[amenity].isnull().sum()} ({train_x[amenity].isnull().mean() * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the rest of empty values, let's fill them with the mean value for that amenity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining NaN values in amenities with the mean value for each amenity\n",
    "for col in amenities:\n",
    "    train_x[col] = train_x[col].fillna(train_x[col].mean())\n",
    "    val_x[col] = val_x[col].fillna(val_x[col].mean())\n",
    "    test_x[col] = test_x[col].fillna(test_x[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused columns\n",
    "After analyze all the features, let's get rid of the useless columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',\n",
       "       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
       "       'Name', 'Group', 'numMembers', 'isHomeEarth', 'isHomeEuropa',\n",
       "       'CabinDeck', 'CabinNum', 'CabinSide', 'isTrappist', 'isCancri'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['PassengerId', 'HomePlanet', 'Cabin', 'Destination', 'Name', 'Group', 'CabinDeck', 'CabinNum', 'CabinSide']\n",
    "train_x = train_x.drop(columns=columns_to_drop)\n",
    "val_x = val_x.drop(columns=columns_to_drop)\n",
    "test_x = test_x.drop(columns=columns_to_drop)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
